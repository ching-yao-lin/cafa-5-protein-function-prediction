{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajW0YowJURIe"
      },
      "source": [
        "# [PROTGOAT paper](https://www.biorxiv.org/content/10.1101/2024.04.01.587572v1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BlSCyHpURIg"
      },
      "source": [
        "## Legacy code from original github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9k3OGKjvURIh"
      },
      "outputs": [],
      "source": [
        "# # Legacy code from orignal github\n",
        "# txt_dim1 = 200\n",
        "# txt_dim2 = 200\n",
        "\n",
        "# def extract_go_terms_and_branches(file_path):\n",
        "#     with open(file_path, 'r') as file:\n",
        "#         content = file.read()\n",
        "#         # Match each stanza with [Term] in the OBO file\n",
        "#         stanzas = re.findall(r'\\[Term\\][\\s\\S]*?(?=\\n\\[|$)', content)\n",
        "\n",
        "#     go_terms_dict = {}\n",
        "#     for stanza in stanzas:\n",
        "#         # Extract the GO term ID\n",
        "#         go_id = re.search(r'^id: (GO:\\d+)', stanza, re.MULTILINE)\n",
        "#         if go_id:\n",
        "#             go_id = go_id.group(1)\n",
        "\n",
        "#         # Extract the namespace (branch)\n",
        "#         namespace = re.search(r'^namespace: (\\w+)', stanza, re.MULTILINE)\n",
        "#         if namespace:\n",
        "#             namespace = namespace.group(1)\n",
        "\n",
        "#         if go_id and namespace:\n",
        "#             # Map the branch abbreviation to the corresponding BPO, CCO, or MFO\n",
        "#             branch_abbr = {'biological_process': 'BPO', 'cellular_component': 'CCO', 'molecular_function': 'MFO'}\n",
        "#             go_terms_dict[go_id] = branch_abbr[namespace]\n",
        "\n",
        "#     return go_terms_dict\n",
        "\n",
        "# def get_constr_out(x, R):\n",
        "#     \"\"\" Given the output of the neural network x returns the output of MCM given the hierarchy constraint expressed in the matrix R \"\"\"\n",
        "#     c_out = tf.cast(x, tf.float32)\n",
        "#     print('c_out1', c_out.shape)\n",
        "#     c_out = tf.expand_dims(c_out, 1)\n",
        "#     print('c_out2', c_out.shape)\n",
        "#     c_out = tf.tile(c_out, [1, tf.shape(R)[1], 1])\n",
        "#     print('c_out3', c_out.shape)\n",
        "#     # c_out = tf.expand_dims(c_out, -2)  # Expand the last dimension of c_out\n",
        "#     # print('c_out2', c_out.shape)\n",
        "#     # c_out = tf.tile(c_out, [1, tf.shape(R)[1]], 1)  # Make c_out match the shape of R\n",
        "#     # print('c_out3', c_out.shape)\n",
        "#     R = tf.cast(R, tf.float32)\n",
        "#     print('R', R.shape)\n",
        "#     R = tf.expand_dims(R, axis=0)  # make R 3D by adding an extra dimension\n",
        "#     print('R', R.shape)\n",
        "#     R_batch = tf.tile(R, [tf.shape(x)[0], 1, 1])  # replicate R along the batch dimension\n",
        "#     print('R_batch', R_batch.shape)\n",
        "#     print(R_batch[0][50][0:50])\n",
        "#     print(c_out[0][0][:50])\n",
        "#     final_out = tf.reduce_max(R_batch * c_out, axis=2)\n",
        "#     print('final_out', final_out.shape)\n",
        "#     return final_out\n",
        "\n",
        "\n",
        "# class CustomMCM(Loss):\n",
        "#     def __init__(self, R, name=\"custom_mcm\"):\n",
        "#         super().__init__(name=name)\n",
        "#         self.R = tf.cast(R, tf.float32)\n",
        "\n",
        "#     def call(self, y_true, y_pred):\n",
        "#         constr_output = get_constr_out(y_pred, self.R)\n",
        "#         y_true = tf.cast(y_true, tf.float32)\n",
        "#         print('yt, yp, c_out', y_true.shape, y_pred.shape, constr_output.shape)\n",
        "\n",
        "#         train_output = y_true * y_pred\n",
        "#         print('train_output1', train_output.shape)\n",
        "\n",
        "#         train_output = get_constr_out(train_output, self.R)\n",
        "#         print('train_output2', train_output.shape)\n",
        "\n",
        "#         train_output = (1-y_true)*constr_output + y_true*train_output\n",
        "#         print('train_output3', train_output.shape)\n",
        "\n",
        "#         # return binary cross entropy loss\n",
        "#         # return K.mean(K.binary_crossentropy(y_true, train_output), axis=-1) #this does not make things better -1 -> -2\n",
        "#         return tf.keras.losses.binary_crossentropy(y_true, train_output)\n",
        "\n",
        "# class ProteinPredictions:\n",
        "#     # Initialize an empty dictionary to store the predictions\n",
        "#     def __init__(self):\n",
        "#         self.predictions = {}\n",
        "\n",
        "#     # Add a prediction to the storage, with optional bonus\n",
        "#     # Arguments:\n",
        "#     #   - protein: Identifier for the protein\n",
        "#     #   - go_term: GO term that is being predicted\n",
        "#     #   - score: Confidence score of the prediction\n",
        "#     #   - branch: Branch of the Gene Ontology (e.g., 'CCO', 'MFO', 'BPO')\n",
        "#     #   - bonus: Optional bonus to be added to the score\n",
        "#     def add_prediction(self, protein, go_term, score, branch, bonus=1, adjustment=1):\n",
        "#         # If the protein is not already in the storage, initialize its structure\n",
        "#         if protein not in self.predictions:\n",
        "#             self.predictions[protein] = {'CCO': {}, 'MFO': {}, 'BPO': {}}\n",
        "\n",
        "#         # Convert the score to a float for comparison and calculation\n",
        "#         score = float(score)\n",
        "\n",
        "#         # If this GO term has already been predicted for this protein and branch,\n",
        "#         # add the bonus to the score. Keep the highest score.\n",
        "#         if go_term in self.predictions[protein][branch]:\n",
        "#             self.predictions[protein][branch][go_term] *= 1+(score**3)*bonus\n",
        "#             self.predictions[protein][branch][go_term] += score*adjustment\n",
        "\n",
        "#         # If this GO term has not been predicted yet, store it with the score\n",
        "#         else:\n",
        "#             self.predictions[protein][branch][go_term] = max(score*adjustment, 0)\n",
        "\n",
        "#         # Ensure that the score does not exceed 1\n",
        "#         if self.predictions[protein][branch][go_term] > 1:\n",
        "#             self.predictions[protein][branch][go_term] = 1\n",
        "\n",
        "#     # Get a list of all scores in the predictions\n",
        "#     def get_scores(self):\n",
        "#         scores = []\n",
        "#         for protein, branches in self.predictions.items():\n",
        "#             for branch, go_terms in branches.items():\n",
        "#                 scores.extend(go_terms.values())\n",
        "#         return scores\n",
        "\n",
        "#     def plot_predictions(self):\n",
        "#         scores = self.get_scores()\n",
        "#         plt.hist(scores, bins=30, edgecolor='black')\n",
        "#         plt.title('Distribution of Prediction Scores')\n",
        "#         plt.xlabel('Score')\n",
        "#         plt.ylabel('Frequency')\n",
        "#         plt.show()\n",
        "\n",
        "#     # Export the stored predictions to a file\n",
        "#     # Arguments:\n",
        "#     #   - output_file: File name for the exported predictions\n",
        "#     #   - top: Number of top predictions to export for each protein and branch\n",
        "#     def get_predictions(self, output_file='submission.tsv', top=60):\n",
        "#         # Open the output file\n",
        "#         with open(output_file, 'w') as f:\n",
        "#             # Iterate through each protein and its branches\n",
        "#             for protein, branches in self.predictions.items():\n",
        "#                 # For each branch, sort the GO terms by score in descending order and select the top ones\n",
        "#                 for branch, go_terms in branches.items():\n",
        "#                     # Sort go_terms by score in descending order and take the top ones\n",
        "#                     top_go_terms = sorted(go_terms.items(), key=lambda x: x[1], reverse=True)[:top]\n",
        "#                     # Write each of the top predictions to the file\n",
        "#                     for go_term, score in top_go_terms:\n",
        "#                         f.write(f\"{protein}\\t{go_term}\\t{score:.3f}\\n\")\n",
        "\n",
        "# file_path = os.path.join(TRAIN_DIR, 'go-basic.obo')\n",
        "# go_terms_dict = extract_go_terms_and_branches(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLZC3Ge8cxaI"
      },
      "outputs": [],
      "source": [
        "# class TrainingDataPreparation:\n",
        "#     \"\"\"Prepares training data depending on which ontology is being looked at\"\"\"\n",
        "\n",
        "#     def __init__(self, ontology: str, verbose: bool = False):\n",
        "#         self.ontology = ontology\n",
        "#         self.verbose = verbose\n",
        "\n",
        "#     def load_Y_data(self):\n",
        "\n",
        "#         if self.ontology not in N_EXTRACTED_TERMS.keys():\n",
        "#             print('Error: ontology not recognized')\n",
        "#             return None, None, None\n",
        "\n",
        "#         # Set up file paths\n",
        "#         onto_abbr = self.ontology[:2]\n",
        "#         n_extracted_terms = N_EXTRACTED_TERMS[self.ontology]\n",
        "\n",
        "#         Y_filepath = os.path.join(EMBEDDING_DIR, f'Y_{onto_abbr}_{n_extracted_terms}.npy')\n",
        "#         Y_labels_filepath = os.path.join(EMBEDDING_DIR, f'Y_{onto_abbr}_labels_{n_extracted_terms}.npy')\n",
        "#         df_filepath = os.path.join(EMBEDDING_DIR, f'{self.ontology}_{n_extracted_terms}_freq_weights.csv')\n",
        "\n",
        "#         # Load data\n",
        "#         Y = np.load(Y_filepath, allow_pickle=True)\n",
        "#         Y_labels = np.load(Y_labels_filepath, allow_pickle=True)\n",
        "#         df = pd.read_csv(df_filepath)\n",
        "#         weights_raw = df['IA_weight'].values.tolist()\n",
        "#         weights = {i: weights_raw[i] for i in range(len(weights_raw))}\n",
        "\n",
        "#         if self.verbose:\n",
        "#             print(f'Loaded {self.ontology} ontology')\n",
        "\n",
        "#         return Y, Y_labels, weights, df\n",
        "\n",
        "#     def load_t5_data(self):\n",
        "#         train_data1 = np.load(os.path.join(EMBEDDING_DIR, 't5_train_data_sorted_f32.npy'), mmap_mode='r')\n",
        "#         test_data1 = np.load(os.path.join(EMBEDDING_DIR, 't5_test_data_sorted_f32.npy'), mmap_mode='r')\n",
        "#         if self.verbose:\n",
        "#             print(f'T5 train data shape: {train_data1.shape}')\n",
        "#             print(f'T5 test data shape: {test_data1.shape}')\n",
        "\n",
        "#         return train_data1, test_data1\n",
        "\n",
        "#     def load_esm2_s_data(self):\n",
        "#         train_data2 = np.load(os.path.join(EMBEDDING_DIR, 'esm2_train_data_sorted_f32.npy'), mmap_mode='r')\n",
        "#         test_data2 = np.load(os.path.join(EMBEDDING_DIR, 'esm2_test_data_sorted_f32.npy'), mmap_mode='r')\n",
        "#         if self.verbose:\n",
        "#             print(f'ESM2 small train data shape: {train_data2.shape}')\n",
        "#             print(f'ESM2 small test data shape: {test_data2.shape}')\n",
        "\n",
        "#         return train_data2, test_data2\n",
        "\n",
        "#     def load_esm2_l_data(self):\n",
        "#         train_data3 = np.load(os.path.join(EMBEDDING_DIR, 'ESM2_3B_train_embeddings_sorted.npy'), mmap_mode='r')\n",
        "#         test_data3 = np.load(os.path.join(EMBEDDING_DIR, 'ESM2_3B_test_embeddings_sorted.npy'), mmap_mode='r')\n",
        "#         if self.verbose:\n",
        "#             print(f'ESM2 3B train data shape: {train_data3.shape}')\n",
        "#             print(f'ESM2 3B data shape: {test_data3.shape}')\n",
        "\n",
        "#         return train_data3, test_data3\n",
        "\n",
        "#     def load_pb_data(self):\n",
        "#         train_data4 = np.load(os.path.join(EMBEDDING_DIR, 'pb_train_data_sorted_f32.npy'), mmap_mode='r')\n",
        "#         test_data4 = np.load(os.path.join(EMBEDDING_DIR, 'pb_test_data_sorted_f32.npy'), mmap_mode='r')\n",
        "#         if self.verbose:\n",
        "#             print(f'PB train data shape: {train_data4.shape}')\n",
        "#             print(f'PB data shape: {test_data4.shape}')\n",
        "\n",
        "#         return train_data4, test_data4\n",
        "\n",
        "#     def load_ankh_data(self):\n",
        "#         train_data5 = np.load(os.path.join(EMBEDDING_DIR, 'Ankh_train_embeddings_sorted.npy'), mmap_mode='r')\n",
        "#         test_data5 = np.load(os.path.join(EMBEDDING_DIR, 'Ankh_test_embeddings_sorted.npy'), mmap_mode='r')\n",
        "#         if self.verbose:\n",
        "#             print(f'Ankh train data shape: {train_data5.shape}')\n",
        "#             print(f'Ankh data shape: {test_data5.shape}')\n",
        "\n",
        "#         return train_data5, test_data5\n",
        "\n",
        "#     def load_taxa_data(self):\n",
        "#         train_data6 = np.load(os.path.join(EMBEDDING_DIR, 'protein_taxa_matrix_train.npy'), mmap_mode='r')\n",
        "#         test_data6 = np.load(os.path.join(EMBEDDING_DIR, 'protein_taxa_matrix_test.npy'), mmap_mode='r')\n",
        "\n",
        "#         train_data6 = np.expand_dims(train_data6, axis=1)\n",
        "#         test_data6 = np.expand_dims(test_data6, axis=1)\n",
        "#         if self.verbose:\n",
        "#             print(f'Taxa train data shape: {train_data6.shape}')\n",
        "#             print(f'Taxa data shape: {test_data6.shape}')\n",
        "\n",
        "#         return train_data6, test_data6\n",
        "\n",
        "#     def load_text_embed(self):\n",
        "\n",
        "#         train_data7 = np.load(os.path.join(EMBEDDING_DIR, 'Text_abstract_embeds_train_sorted.npy'), mmap_mode='r')\n",
        "#         test_data7 = np.load(os.path.join(EMBEDDING_DIR, 'Text_abstract_embeds_test_sorted.npy'), mmap_mode='r')\n",
        "#         if self.verbose:\n",
        "#             print(f'Text abstract data shape: {train_data7.shape}')\n",
        "#             print(f'Text abstract shape: {test_data7.shape}')\n",
        "\n",
        "#         return train_data7, test_data7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU8rQ-p6URIj"
      },
      "source": [
        "## Project Scaffolding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt8pxeguURIj"
      },
      "source": [
        "### Imports and Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1tnsKR1Uzti",
        "outputId": "74a3ea39-a3fb-451e-8e5f-156b9f148515"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path_embeddings = '/content/drive/Shared drives/CAFA-5: ECEN766 Final Project/PROTGOAT_embeddings'\n"
      ],
      "metadata": {
        "id": "qdle-EEDVl_H"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "embeddings_all=os.listdir(folder_path_embeddings)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "suUZX8aFWGCx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install cafaeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXhsRztdW3W2",
        "outputId": "4be82e9c-2f16-4873-885f-b7d52bc7835e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cafaeval\n",
            "  Downloading cafaeval-1.2.1-py3-none-any.whl (69 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/69.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.5/69.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from cafaeval) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from cafaeval) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from cafaeval) (1.25.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cafaeval) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cafaeval) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cafaeval) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cafaeval) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cafaeval) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cafaeval) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cafaeval) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cafaeval) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->cafaeval) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->cafaeval) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->cafaeval) (1.16.0)\n",
            "Installing collected packages: cafaeval\n",
            "Successfully installed cafaeval-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall preprocess -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odSqZEZOXAzt",
        "outputId": "5bb60f01-f9aa-403c-beb0-7c2d6144cb55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: preprocess 2.0.0\n",
            "Uninstalling preprocess-2.0.0:\n",
            "  Successfully uninstalled preprocess-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall parameters -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWMxVU2aXwyr",
        "outputId": "f1b5ee5f-394e-4033-bf8f-1b70e9838c3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: parameters 0.2.1\n",
            "Uninstalling parameters-0.2.1:\n",
            "  Successfully uninstalled parameters-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeuOmTWLqLsB",
        "outputId": "b5955cb5-cf35-4508-cf76-6a2179f32e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.15.0\n",
            "Uninstalling tensorflow-2.15.0:\n",
            "  Successfully uninstalled tensorflow-2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nge_5ITyqr4s",
        "outputId": "86bfed0e-d2a4-476b-9db9-530b1f17f397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Collecting h5py>=3.10.0 (from tensorflow)\n",
            "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras>=3.0.0 (from tensorflow)\n",
            "  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
            "Collecting namex (from keras>=3.0.0->tensorflow)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Collecting optree (from keras>=3.0.0->tensorflow)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
            "Installing collected packages: namex, optree, ml-dtypes, h5py, tensorboard, keras, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h5py-3.11.0 keras-3.3.3 ml-dtypes-0.3.2 namex-0.0.8 optree-0.11.0 tensorboard-2.16.2 tensorflow-2.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUfIswnHarKY",
        "outputId": "2ee2de16-ef3b-4d72-aee8-6e6dde03d56f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/Shareddrives/CAFA-5: ECEN766 Final Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"drive/Shareddrives/CAFA-5: ECEN766 Final Project\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzmBvnrQarB1",
        "outputId": "56c0b78a-b381-4947-f16c-088f8af12ac0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/Shareddrives/CAFA-5: ECEN766 Final Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install Bio obonet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFNnxYmybqY7",
        "outputId": "bd0b5dd7-472e-4109-e390-09bf0eeba46e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Bio\n",
            "  Downloading bio-1.7.0-py3-none-any.whl (279 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/279.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m276.5/279.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.2/279.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting obonet\n",
            "  Downloading obonet-1.0.0-py3-none-any.whl (9.2 kB)\n",
            "Collecting biopython>=1.80 (from Bio)\n",
            "  Downloading biopython-1.83-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gprofiler-official (from Bio)\n",
            "  Downloading gprofiler_official-1.0.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting mygene (from Bio)\n",
            "  Downloading mygene-3.2.2-py2.py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from Bio) (2.0.3)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.10/dist-packages (from Bio) (1.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from Bio) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from Bio) (4.66.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from obonet) (3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython>=1.80->Bio) (1.25.2)\n",
            "Collecting biothings-client>=0.2.6 (from mygene->Bio)\n",
            "  Downloading biothings_client-0.3.1-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->Bio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->Bio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->Bio) (2024.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch->Bio) (4.2.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch->Bio) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->Bio) (1.16.0)\n",
            "Installing collected packages: obonet, biopython, gprofiler-official, biothings-client, mygene, Bio\n",
            "Successfully installed Bio-1.7.0 biopython-1.83 biothings-client-0.3.1 gprofiler-official-1.0.0 mygene-3.2.2 obonet-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GVP3d-63bpt4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import itertools\n",
        "import functools\n",
        "import os\n",
        "import gc\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from enum import Enum\n",
        "from pathlib import Path\n",
        "\n",
        "from typing import Dict, Callable, Sequence, Iterable, Iterator, Tuple, Optional, Any\n",
        "from numpy.typing import NDArray, ArrayLike, DTypeLike\n",
        "from sklearn.model_selection._split import _BaseKFold\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, Callback, CSVLogger\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU, Concatenate, Input, ReLU, MultiHeadAttention\n",
        "from tensorflow.keras.utils import plot_model, register_keras_serializable, set_random_seed\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import Loss\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "\n",
        "\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "from sklearn.model_selection import KFold, ShuffleSplit, train_test_split, TimeSeriesSplit\n",
        "from sklearn.metrics import roc_auc_score, multilabel_confusion_matrix, precision_recall_curve, auc\n",
        "\n",
        "# Evaluation for CAFA5\n",
        "import cafaeval\n",
        "from cafaeval.evaluation import cafa_eval, write_results\n",
        "\n",
        "# >>> res = cafa_eval(\"IDPO_disorder_function.obo\", \"predictions\", \"ground_truth.tsv\")\n",
        "# >>> write_results(*res)\n",
        "# from sklearn.linear_model import Ridge, LinearRegression\n",
        "# from sklearn.neighbors import KNeighborsRegressor\n",
        "# from sklearn.neural_network import MLPRegressor\n",
        "# from scipy.stats import rankdata, norm\n",
        "# from scipy.sparse import load_npz\n",
        "\n",
        "# Self-defined modules\n",
        "import preprocess\n",
        "from parameters import CrossValidationParameters, TrainingParameters, ModelParameters\n",
        "\n",
        "# Cell Output Formatting\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "# Custom Types\n",
        "KFoldSplitIndicesTuple = Tuple[int, Tuple[NDArray[int], NDArray[int]]]\n",
        "\n",
        "# Force to use CPU!!\n",
        "#tf.config.set_visible_devices([], 'GPU')\n",
        "# print(tf.config.list_physical_devices())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIR = embeddings_all"
      ],
      "metadata": {
        "id": "1FpOm1wYYuaI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JBmHVCH9URIk"
      },
      "outputs": [],
      "source": [
        "# Project directories\n",
        "EMBEDDING_DIR = Path(\"PROTGOAT_embeddings\")\n",
        "TRAIN_DIR = Path(\"Train\")\n",
        "TEST_DIR = Path(\"Test (Targets)\")\n",
        "MODEL_SAVE_DIR = Path(\"models\")\n",
        "MODEL_LOGS_SAVE_DIR = Path(\"model_logs\")\n",
        "PREDICTION_DIR = Path(\"predictions\")\n",
        "SUBMISSION_DIR = Path(\"final_submissions\")\n",
        "\n",
        "# Utility constants\n",
        "BRANCH_ABBR = {'biological_process': 'BPO', 'cellular_component': 'CCO', 'molecular_function': 'MFO'}\n",
        "N_EXTRACTED_TERMS = {\"BPO\": 1500, \"CCO\": 800, \"MFO\": 800}\n",
        "MODEL_FILENAME_TEMPLATE = \"{model_name}_{ontology}_fc{fold_ct}_r{rand_seed}\"\n",
        "MODEL_CV_FILENAME_TEMPLATE = \"{model_name}_{ontology}_fc{fold_ct}_r{rand_seed}_cv\"\n",
        "MODEL_TSS_FILENAME_TEMPLATE = \"{model_name}_{ontology}_r{rand_seed}_tss\"\n",
        "\n",
        "ONTOLOGY_SUBMISSION_TEMPLATE = \"{ontology}_{model_name}.tsv\"\n",
        "ONTOLOGY_FOLD_PREDICTION_TEMPLATE = \"{ontology}_{model_name}_{fold_ct}.tsv\"\n",
        "ONTOLOGY_TSS_PREDICTION_TEMPLATE = \"{ontology}_{model_name}_tss.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBslHpVPc0zA",
        "outputId": "bac43cc1-4024-4565-aa11-bd9539889653"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('PROTGOAT_embeddings')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1s8ccwVURIk"
      },
      "source": [
        "### Create missing data in PROTGOAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2Siz7jYURIk"
      },
      "outputs": [],
      "source": [
        "# # Read in train data\n",
        "# train_sequences_fasta, train_taxonomy, train_terms, go_graph, information_accretion = preprocess.load_train_data(TRAIN_DIR)\n",
        "# # Read in test data\n",
        "# test_sequences_fasta, test_taxonomy = preprocess.load_test_data(TEST_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vAQ5x60URIk"
      },
      "outputs": [],
      "source": [
        "# go_terms_ontology = {}\n",
        "# for go_id, go_node in go_graph.nodes.items():\n",
        "#     go_terms_ontology[go_id] = BRANCH_ABBR[go_node[\"namespace\"]]\n",
        "\n",
        "# len(go_terms_ontology) # 43248\n",
        "# len(go_terms_dict)     # 47417"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GfF_ldpURIl"
      },
      "source": [
        "Create `\"*_*_freq_weights.csv\"` data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldFvQJOnURIl"
      },
      "outputs": [],
      "source": [
        "# # Get the weights: freq * IA\n",
        "# train_terms_IA_freq = (\n",
        "#     train_terms\n",
        "#     .groupby([\"aspect\", \"term\"])[\"EntryID\"].count()\n",
        "#     .reset_index()\n",
        "#     .rename(columns={\"EntryID\": \"freq\"})\n",
        "#     .merge(information_accretion, left_on=\"term\", right_on=\"GO_term\")\n",
        "#     [[\"aspect\", \"GO_term\", \"freq\", \"IA\"]]\n",
        "#     .pipe(lambda df: df.assign(IA_weight=df.IA * df.freq))\n",
        "# )\n",
        "\n",
        "# # Write to files for each aspect\n",
        "# for aspect, n_terms in N_EXTRACTED_TERMS.items():\n",
        "#     save_filename = os.path.join(EMBEDDING_DIR, f\"{aspect}_{n_terms}_freq_weights.csv\")\n",
        "#     train_terms_IA_freq.query(\"aspect == @aspect\").nlargest(n_terms, columns=\"IA_weight\").to_csv(save_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axp_DgFDURIl"
      },
      "source": [
        "Create `protein_taxa_matrix_*` data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3u8ulq1URIl"
      },
      "outputs": [],
      "source": [
        "# # Preprocess the train sequences\n",
        "# train_sequences = preprocess.create_sequence_dataframe_from_fasta(train_sequences_fasta)\n",
        "# train_sequences = preprocess.augment_train_features_from_fasta_description(train_sequences)\n",
        "# train_sequences = train_sequences.merge(train_taxonomy, on=\"EntryID\", how=\"left\").drop_duplicates()\n",
        "\n",
        "# # Preprocess the test sequences\n",
        "# test_sequences = preprocess.create_sequence_dataframe_from_fasta(test_sequences_fasta)\n",
        "# test_sequences = preprocess.augment_test_features_from_fasta_description(test_sequences)\n",
        "# test_sequences = test_sequences.merge(test_taxonomy, on=\"ID\", how=\"left\").drop_duplicates()\n",
        "\n",
        "# print(f\"{train_sequences.shape = }\")\n",
        "# print(f\"{test_sequences.shape = }\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFPK6FrHURIl"
      },
      "outputs": [],
      "source": [
        "# # Write to files\n",
        "# with open(os.path.join(EMBEDDING_DIR, 'protein_taxa_matrix_train.npy'), 'wb') as f:\n",
        "#     np.save(f, train_sequences.taxonomyID.values)\n",
        "\n",
        "# with open(os.path.join(EMBEDDING_DIR, 'protein_taxa_matrix_test.npy'), 'wb') as f:\n",
        "#     np.save(f, test_sequences.ID.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0-7F6vIURIm"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "xJwTSiyTURIm",
        "outputId": "ab56fb2c-d359-4715-d9aa-dcf1c8ec49cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   tss_train  tss_val  count       pct\n",
              "0       True    False  50337  0.597380\n",
              "1      False     True  17065  0.202521\n",
              "2      False    False  16861  0.200100"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-660400f9-651b-4b57-aeb4-d51db4082d17\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tss_train</th>\n",
              "      <th>tss_val</th>\n",
              "      <th>count</th>\n",
              "      <th>pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>50337</td>\n",
              "      <td>0.597380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>17065</td>\n",
              "      <td>0.202521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>16861</td>\n",
              "      <td>0.200100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-660400f9-651b-4b57-aeb4-d51db4082d17')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-660400f9-651b-4b57-aeb4-d51db4082d17 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-660400f9-651b-4b57-aeb4-d51db4082d17');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-921d18df-6271-44ac-a7d0-87818f974d9b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-921d18df-6271-44ac-a7d0-87818f974d9b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-921d18df-6271-44ac-a7d0-87818f974d9b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \")\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"tss_train\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tss_val\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19268,\n        \"min\": 16861,\n        \"max\": 50337,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          50337,\n          17065\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pct\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2286740070555692,\n        \"min\": 0.20009968788198854,\n        \"max\": 0.5973796328163014,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5973796328163014,\n          0.2025206793017101\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "train_sequences = preprocess.get_train_sequences(TRAIN_DIR)\n",
        "\n",
        "train_percentage = 0.6\n",
        "val_percentage = 0.2\n",
        "\n",
        "time_series_batch_split = (\n",
        "    train_sequences\n",
        "    .dropna(subset=\"first_release\")\n",
        "    .sort_values(\"first_release\")\n",
        "    .groupby(\"first_release\")[[\"EntryID\"]].count()\n",
        "    .rename(columns={\"EntryID\": \"n_released\"})\n",
        "    .assign(\n",
        "        cum_pct=lambda df: df.cumsum() / df.sum(),\n",
        "        tss_train=lambda df: df.cum_pct <= train_percentage,\n",
        "        tss_val=lambda df: (train_percentage < df.cum_pct) & (df.cum_pct <= train_percentage + val_percentage)\n",
        "    )\n",
        ")\n",
        "\n",
        "# To check the split data percentages\n",
        "(\n",
        "    train_sequences\n",
        "    .merge(time_series_batch_split[[\"tss_train\", \"tss_val\"]], left_on=\"first_release\", right_index=True, how=\"left\")\n",
        "    [[\"tss_train\", \"tss_val\"]]\n",
        "    .value_counts()\n",
        "    .to_frame()\n",
        "    .reset_index()\n",
        "    .pipe(lambda df: df.assign(pct=df[\"count\"] / df[\"count\"].sum()))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "gRTKKpFY69jH",
        "outputId": "94d3fcf5-acff-4204-b74c-3589d1e155d2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           EntryID                                           sequence  \\\n",
              "0           P20536  MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...   \n",
              "1           O73864  MTEYRNFLLLFITSLSVIYPCTGISWLGLTINGSSVGWNQTHHCKL...   \n",
              "2           O95231  MRLSSSPPRGPQQLSSFGSVDWLSQSSCSGPTHTPRPADFSLGSLP...   \n",
              "3       A0A0B4J1F4  MGGEAGADGPRGRVKSLGLVFEDESKGCYSSGETVAGHVLLEAAEP...   \n",
              "4           P54366  MVETNSPPAGYTLKRSPSDLGEQQQPPRQISRSPGNTAAYHLTTAM...   \n",
              "...            ...                                                ...   \n",
              "142241  A0A286YAI0  METEVDDFPGKASIFSQVNPLYSNNMKLCEAERYDFQHSEPKTMKS...   \n",
              "142242  A0A1D5NUC4  MSAAASAEMIETPPVLNFEEIDYKEIEVEEVVGRGAFGVVCKAKWR...   \n",
              "142243      Q5RGB0  MADKGPILTSVIIFYLSIGAAIFQILEEPNLNSAVDDYKNKTNNLL...   \n",
              "142244  A0A2R8QMZ5  MGRKKIQITRIMDERNRQVTFTKRKFGLMKKAYELSVLCDCEIALI...   \n",
              "142245  A0A8I6GHU0  HCISSLKLTAFFKRSFLLSPEKHLVLLRDGRTLIGFLRSIDQFANL...   \n",
              "\n",
              "        organism_id  taxonomyID first_release  \n",
              "0           10249.0       10249    1991-02-01  \n",
              "1            7955.0        7955    2002-01-23  \n",
              "2            9606.0        9606    2007-10-02  \n",
              "3           10090.0       10090    2015-12-09  \n",
              "4            7227.0        7227    1996-10-01  \n",
              "...             ...         ...           ...  \n",
              "142241       7955.0        7955           NaT  \n",
              "142242       9031.0        9031           NaT  \n",
              "142243       7955.0        7955           NaT  \n",
              "142244       7955.0        7955           NaT  \n",
              "142245      10116.0       10116           NaT  \n",
              "\n",
              "[142246 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d968db06-2907-4ebd-be39-ae8697a0c810\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EntryID</th>\n",
              "      <th>sequence</th>\n",
              "      <th>organism_id</th>\n",
              "      <th>taxonomyID</th>\n",
              "      <th>first_release</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P20536</td>\n",
              "      <td>MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...</td>\n",
              "      <td>10249.0</td>\n",
              "      <td>10249</td>\n",
              "      <td>1991-02-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>O73864</td>\n",
              "      <td>MTEYRNFLLLFITSLSVIYPCTGISWLGLTINGSSVGWNQTHHCKL...</td>\n",
              "      <td>7955.0</td>\n",
              "      <td>7955</td>\n",
              "      <td>2002-01-23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O95231</td>\n",
              "      <td>MRLSSSPPRGPQQLSSFGSVDWLSQSSCSGPTHTPRPADFSLGSLP...</td>\n",
              "      <td>9606.0</td>\n",
              "      <td>9606</td>\n",
              "      <td>2007-10-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A0A0B4J1F4</td>\n",
              "      <td>MGGEAGADGPRGRVKSLGLVFEDESKGCYSSGETVAGHVLLEAAEP...</td>\n",
              "      <td>10090.0</td>\n",
              "      <td>10090</td>\n",
              "      <td>2015-12-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P54366</td>\n",
              "      <td>MVETNSPPAGYTLKRSPSDLGEQQQPPRQISRSPGNTAAYHLTTAM...</td>\n",
              "      <td>7227.0</td>\n",
              "      <td>7227</td>\n",
              "      <td>1996-10-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142241</th>\n",
              "      <td>A0A286YAI0</td>\n",
              "      <td>METEVDDFPGKASIFSQVNPLYSNNMKLCEAERYDFQHSEPKTMKS...</td>\n",
              "      <td>7955.0</td>\n",
              "      <td>7955</td>\n",
              "      <td>NaT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142242</th>\n",
              "      <td>A0A1D5NUC4</td>\n",
              "      <td>MSAAASAEMIETPPVLNFEEIDYKEIEVEEVVGRGAFGVVCKAKWR...</td>\n",
              "      <td>9031.0</td>\n",
              "      <td>9031</td>\n",
              "      <td>NaT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142243</th>\n",
              "      <td>Q5RGB0</td>\n",
              "      <td>MADKGPILTSVIIFYLSIGAAIFQILEEPNLNSAVDDYKNKTNNLL...</td>\n",
              "      <td>7955.0</td>\n",
              "      <td>7955</td>\n",
              "      <td>NaT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142244</th>\n",
              "      <td>A0A2R8QMZ5</td>\n",
              "      <td>MGRKKIQITRIMDERNRQVTFTKRKFGLMKKAYELSVLCDCEIALI...</td>\n",
              "      <td>7955.0</td>\n",
              "      <td>7955</td>\n",
              "      <td>NaT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142245</th>\n",
              "      <td>A0A8I6GHU0</td>\n",
              "      <td>HCISSLKLTAFFKRSFLLSPEKHLVLLRDGRTLIGFLRSIDQFANL...</td>\n",
              "      <td>10116.0</td>\n",
              "      <td>10116</td>\n",
              "      <td>NaT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>142246 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d968db06-2907-4ebd-be39-ae8697a0c810')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d968db06-2907-4ebd-be39-ae8697a0c810 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d968db06-2907-4ebd-be39-ae8697a0c810');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e26c22a0-7c54-4556-85e6-af37533783dd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e26c22a0-7c54-4556-85e6-af37533783dd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e26c22a0-7c54-4556-85e6-af37533783dd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_sequences"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Merging the struct embed output to train sequences"
      ],
      "metadata": {
        "id": "pYrYarxD-JeR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Size of Data**"
      ],
      "metadata": {
        "id": "80BEinjOFWRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reading struct.csv and hstacking the struct embedding**"
      ],
      "metadata": {
        "id": "Ce4jBSEeFeFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/Shared drives/CAFA-5: ECEN766 Final Project/Train_Structural_Embeddings_All.csv'\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "gDFfGEgwFdQ3",
        "outputId": "eb2051d8-1b7c-4bb5-c867-6ec5fd4a2afe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PDB_ID                                             Labels  \\\n",
              "0  P90895  GO:0007606, GO:0050896, GO:0050913, GO:0009628...   \n",
              "1  P40989  GO:0008152, GO:0032989, GO:0043935, GO:0019953...   \n",
              "2  B7WN72  GO:0030421, GO:0007586, GO:0003008, GO:0007588...   \n",
              "3  Q8C3P7  GO:0019953, GO:0048856, GO:0044270, GO:0016070...   \n",
              "4  Q69Z28  GO:0035295, GO:0072001, GO:0061333, GO:0001658...   \n",
              "\n",
              "                                            Sequence  \n",
              "0  DFLLLVVLLLQLCCVPPRPVLVVQLCVQLVPDPFDRDRQDDDDPCS...  \n",
              "1  DDDDDDYDDDDDDDDDDDDDDDDDDDDDDDDDDFDAPPVGDGDDDD...  \n",
              "2  DPPPVQKAWAWEAEVVVRDIDIDIDGQFDFQLVVLVVVQVPDPDHD...  \n",
              "3  DVVVVVVVVVVVVVLVVVVVVLVVVVVVVVPPPDPDDDDDDDDDDD...  \n",
              "4  DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da3c44c4-5b31-49fe-855d-f368f8e05975\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PDB_ID</th>\n",
              "      <th>Labels</th>\n",
              "      <th>Sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P90895</td>\n",
              "      <td>GO:0007606, GO:0050896, GO:0050913, GO:0009628...</td>\n",
              "      <td>DFLLLVVLLLQLCCVPPRPVLVVQLCVQLVPDPFDRDRQDDDDPCS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P40989</td>\n",
              "      <td>GO:0008152, GO:0032989, GO:0043935, GO:0019953...</td>\n",
              "      <td>DDDDDDYDDDDDDDDDDDDDDDDDDDDDDDDDDFDAPPVGDGDDDD...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B7WN72</td>\n",
              "      <td>GO:0030421, GO:0007586, GO:0003008, GO:0007588...</td>\n",
              "      <td>DPPPVQKAWAWEAEVVVRDIDIDIDGQFDFQLVVLVVVQVPDPDHD...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q8C3P7</td>\n",
              "      <td>GO:0019953, GO:0048856, GO:0044270, GO:0016070...</td>\n",
              "      <td>DVVVVVVVVVVVVVLVVVVVVLVVVVVVVVPPPDPDDDDDDDDDDD...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Q69Z28</td>\n",
              "      <td>GO:0035295, GO:0072001, GO:0061333, GO:0001658...</td>\n",
              "      <td>DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da3c44c4-5b31-49fe-855d-f368f8e05975')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-da3c44c4-5b31-49fe-855d-f368f8e05975 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-da3c44c4-5b31-49fe-855d-f368f8e05975');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d6d1786c-2459-4c7b-81f8-06dbede4e308\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d6d1786c-2459-4c7b-81f8-06dbede4e308')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d6d1786c-2459-4c7b-81f8-06dbede4e308 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Memory crash happens when attemptig to merge so trying to shuffle properly\n",
        "\n",
        "# first_df=train_sequences.EntryID\n",
        "\n",
        "# second_df=df.PDB_ID\n",
        "\n",
        "\n",
        "# # Create a mapping from PDB_IDs in the second table to their indices\n",
        "# pdb_id_to_index = {pdb_id: i for i, pdb_id in enumerate(second_df)}\n",
        "\n",
        "# # Map each EntryID in the first table to these indices\n",
        "# indices_to_reorder = first_df.map(pdb_id_to_index).dropna().astype(int)\n",
        "\n",
        "# if indices_to_reorder.isnull().any():\n",
        "#     print(\"Warning: Some EntryIDs do not have corresponding PDB_IDs and will be excluded.\")\n",
        "\n",
        "# # Filter out any NaN indices if necessary\n",
        "# valid_indices = indices_to_reorder.dropna().astype(int)\n",
        "\n",
        "# # Reorder the data according to these indices\n",
        "# reordered_data = data[valid_indices]\n",
        "\n",
        "# # Saving the reordered data if necessary\n",
        "# np.save('reordered_struct_data.npy', reordered_data)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "20LPyATfODNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# # Right table (reference table, like a subset)\n",
        "# right_df =df.PDB_ID\n",
        "\n",
        "# # Left table (target order, full set)\n",
        "# left_df = train_sequences.EntryID\n",
        "\n",
        "# # Create a mapping from right table PDB_IDs to indices\n",
        "# index_map = {pdb_id: i for i, pdb_id in enumerate(right_df)}\n",
        "\n",
        "# # Map indices for PDB_IDs from the left table; entries without a match get a placeholder (-1)\n",
        "# left_df['index'] = left_df.map(index_map).fillna(-1).astype(int)\n",
        "\n",
        "# reordered_data = np.zeros((len(left_df), data.shape[1]))  # Assume data.shape[1] exists\n",
        "\n",
        "# # Populate the reordered array with existing data according to found indices\n",
        "# for i, idx in enumerate(left_df['index']):\n",
        "#     if idx != -1:  # Only copy data for valid indices\n",
        "#         reordered_data[i] = data[idx]\n",
        "\n",
        "# reordered_data = np.array(reordered_data)  # Replace [your_data_here] with your actual data\n",
        "\n",
        "# # Save the file to Google Drive. Specify the path within your Google Drive\n",
        "# path_in_drive = '/content/drive/My Drive/path_to_your_directory/reordered_struct_data.npy'\n",
        "# np.save(path_in_drive, reordered_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "qyUjyLm3ktrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # Assuming 'reordered_data' is your numpy array that you want to save\n",
        "# reordered_data = np.array(reordered_data)  # Replace [your_data_here] with your actual data\n",
        "\n",
        "# # Save the file to Google Drive. Specify the path within your Google Drive\n"
      ],
      "metadata": {
        "id": "E6POZszJp3Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Read re-order struct\n",
        "\n",
        "path_in_drive = '/content/drive/Shared drives/CAFA-5: ECEN766 Final Project/reordered_struct_embed.npy'\n",
        "data=np.load(path_in_drive)\n"
      ],
      "metadata": {
        "id": "_6DzUKXAyC3r"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequences.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGo6l7fZ8H5P",
        "outputId": "dd412eb5-eb1d-49e4-813f-114e94da046c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(142246, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1=data[0:142246]\n",
        "\n",
        "data1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqP1Xd888CTa",
        "outputId": "bbd79669-b8aa-4d21-b9aa-7225a29a115d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(142246, 21592)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uBZiOCnOURIn"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class OntologyData:\n",
        "    \"\"\"A data-oriented class to load and hold data for a specified ontology\"\"\"\n",
        "\n",
        "    ontology: str                                                # BPO, MFO, CCO\n",
        "    verbose: bool = False\n",
        "    n_terms: int = field(init=False)                             # The number of GO terms considered for this ontology (1500, 800, 800)\n",
        "\n",
        "    # Training data\n",
        "    train_sequences: pd.DataFrame = field(init=False)            # The original training data (with release dates)              (len = N)\n",
        "    train_structures: NDArray = field(init=False)                # The structure embeddings for original training data          (len = N)\n",
        "    X_labels: NDArray[str] = field(init=False)                   # The string EntryID labels of the training sequences          (len = N)\n",
        "\n",
        "    Y: NDArray[NDArray[np.int8]] = field(init=False)             # The one-hot-like multi-labeled ground truths  (N, n_terms)\n",
        "    Y_labels: NDArray[str] = field(init=False)                   # The string labels of the training GO terms    (n_terms,)\n",
        "\n",
        "    weights: Dict[int, float] = field(init=False)\n",
        "    _df_freq_weights: pd.DataFrame = field(init=False)\n",
        "\n",
        "    # Kaggle testing data (Not used)\n",
        "    # test_labels: NDArray = field(init=False)                     # (Not used) The string labels of the testing GO terms for Kaggle\n",
        "    # test_embeddings: Iterable[np.memmap] = field(init=False)     # (Not used) Testing sequence embeddings for Kaggle\n",
        "\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"Automatically load the data\"\"\"\n",
        "        self.n_terms = N_EXTRACTED_TERMS[self.ontology]\n",
        "\n",
        "        self.train_sequences = self.add_tss_split_to_data(preprocess.get_train_sequences(TRAIN_DIR))\n",
        "        self.train_structures = data1\n",
        "        self.X_labels = self.train_sequences[\"EntryID\"].values\n",
        "        # self.test_labels = np.load(os.path.join(EMBEDDING_DIR, 't5_test_labels_sorted.npy'))\n",
        "\n",
        "        # Load the PROTGOAT embeddings\n",
        "        self.Y, self.Y_labels, self.weights, self._df_freq_weights = preprocess.load_Y_data(self.ontology, EMBEDDING_DIR)\n",
        "        self.t5_train, self.t5_test = preprocess.load_t5_data(EMBEDDING_DIR)\n",
        "        self.esm1_train, self.esm1_test = preprocess.load_esm2_s_data(EMBEDDING_DIR)\n",
        "        self.esm2_train, self.esm2_test = preprocess.load_esm2_l_data(EMBEDDING_DIR)\n",
        "        self.pb_train, self.pb_test = preprocess.load_pb_data(EMBEDDING_DIR)\n",
        "        self.ankh_train, self.ankh_test = preprocess.load_ankh_data(EMBEDDING_DIR)\n",
        "        self.taxa_train, self.taxa_test = preprocess.load_taxa_data(EMBEDDING_DIR)\n",
        "\n",
        "        # txt1_train, txt1_test = data_prep.load_text_embed()\n",
        "        # if self.ontology == 'CCO':\n",
        "        #     R = np.load(os.path.join(EMBEDDING_DIR, 'CCO_800_DAG_matrix.npy'))\n",
        "        #     output_split = [4, 11, 24, 59, 199]\n",
        "\n",
        "        # elif self.ontology == 'MFO':\n",
        "        #     R = np.load(os.path.join(EMBEDDING_DIR, 'MFO_800_DAG_matrix.npy'))\n",
        "        #     output_split = [4, 14, 28, 69, 176]\n",
        "\n",
        "        # elif self.ontology == 'BPO':\n",
        "        #     R = np.load(os.path.join(EMBEDDING_DIR, 'BPO_1500_DAG_matrix.npy'))\n",
        "        #     output_split = [13, 45, 102, 213, 465]\n",
        "\n",
        "        if self.verbose:\n",
        "            # print (f'R shape is {R.shape}')\n",
        "            print('datasets loaded')\n",
        "            print(f'Number of proteins with no {self.ontology} terms = {np.sum(np.all(self.Y == 0, axis=1))} out of {self.Y.shape[0]}')\n",
        "\n",
        "\n",
        "    def _get_data_by_indices(self, filter_indices: Sequence[int]):\n",
        "        # Filter out rows in Y\n",
        "        Y_subset = self.Y[filter_indices]\n",
        "\n",
        "        # Filter out rows in other input arrays\n",
        "        t5_subset = self.t5_train[filter_indices]\n",
        "        esm1_subset = self.esm1_train[filter_indices]\n",
        "        esm2_subset = self.esm2_train[filter_indices]\n",
        "        pb_subset = self.pb_train[filter_indices]\n",
        "        ankh_subset = self.ankh_train[filter_indices]\n",
        "        taxa_subset = self.taxa_train[filter_indices]\n",
        "\n",
        "        struct_subset = self.train_structures[filter_indices]\n",
        "\n",
        "        X_labels_subset = self.X_labels[filter_indices]\n",
        "\n",
        "        return (t5_subset, esm1_subset, esm2_subset, pb_subset, ankh_subset, taxa_subset, struct_subset), X_labels_subset, Y_subset\n",
        "\n",
        "\n",
        "    def get_data(self):\n",
        "        self.valid_rows = ~np.all(self.Y == 0, axis=1)\n",
        "        self.embeddings, self.X_labels, self.Y = self._get_data_by_indices(self.valid_rows)\n",
        "        return self.embeddings, self.test_embeddings, (self.Y, self.Y_labels, self.weights)\n",
        "\n",
        "\n",
        "    def get_tss_data(self):\n",
        "\n",
        "        ### Filter the data ###\n",
        "        belongs_to_this_ontology: NDArray[bool] = ~np.all(self.Y == 0, axis=1)   # Only those containing GO terms in this ontology\n",
        "        contains_annotation_dates: NDArray[bool] = self.train_sequences.first_release.notna().values\n",
        "        remove_zero_struct:NDArray[bool]=np.any(data1 != 0, axis=1)\n",
        "\n",
        "        self.valid_rows = belongs_to_this_ontology & contains_annotation_dates & remove_zero_struct#write a condition to exclude all zeros\n",
        "\n",
        "        # Split the data into train, val, test set\n",
        "        is_train_in_tss = self.train_sequences.tss_train.fillna(False).values\n",
        "        is_val_in_tss = self.train_sequences.tss_val.fillna(False).values\n",
        "        is_test_in_tss = ~is_train_in_tss & ~is_val_in_tss & contains_annotation_dates\n",
        "\n",
        "        self.train_rows = self.valid_rows & is_train_in_tss\n",
        "        self.val_rows = self.valid_rows & is_val_in_tss\n",
        "        self.test_rows = self.valid_rows & is_test_in_tss\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f'we retained {self.train_rows.sum()} proteins in training set where {self.ontology} terms are present')\n",
        "            print(f'we retained {self.val_rows.sum()} proteins in validation set where {self.ontology} terms are present')\n",
        "            print(f'we retained {self.test_rows.sum()} proteins in testing set where {self.ontology} terms are present')\n",
        "\n",
        "        return (\n",
        "            self._get_data_by_indices(self.train_rows),\n",
        "            self._get_data_by_indices(self.val_rows),\n",
        "            self._get_data_by_indices(self.test_rows),\n",
        "            (self.Y_labels, self.weights)\n",
        "        )\n",
        "\n",
        "\n",
        "    def get_cv_split_data(\n",
        "            self,\n",
        "            cv_params: CrossValidationParameters,\n",
        "            cv_splitter_class: _BaseKFold = KFold,\n",
        "            val_size: float = 0.2,\n",
        "        ) -> Iterator[KFoldSplitIndicesTuple]:\n",
        "        \"\"\"This method is deprecated for now.\"\"\"\n",
        "\n",
        "        # Set up the cross-validation splitter\n",
        "        cv_splitter = cv_splitter_class(**cv_params._asdict())\n",
        "        split_enumerator: Iterator[KFoldSplitIndicesTuple] = enumerate(\n",
        "            cv_splitter.split(self.embeddings[0]), start=1\n",
        "        )\n",
        "\n",
        "        cv_fold_data = []\n",
        "        for fold_ct, (train_val_index, test_index) in split_enumerator:\n",
        "\n",
        "            # Split the embeddings and labels into train & test set\n",
        "            X_train_vals, X_tests = self.split_X_data(train_val_index, test_index, self.embeddings)\n",
        "            y_train_val, y_test = self.split_y_data(train_val_index, test_index, self.Y)\n",
        "\n",
        "            # Continue to split data into train & val set\n",
        "            train_index, val_index = train_test_split(np.arange(len(train_val_index)),\n",
        "                                                      test_size=val_size, random_state=cv_params.random_state)\n",
        "            X_trains, X_vals = self.split_X_data(train_index, val_index, X_train_vals)\n",
        "            y_train, y_val = self.split_y_data(train_index, val_index, y_train_val)\n",
        "\n",
        "            cv_fold_data.append((fold_ct, X_trains, y_train, X_vals, y_val, X_tests, y_test))\n",
        "\n",
        "        return cv_fold_data\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def add_tss_split_to_data(train_sequences, train_percentage = 0.6, val_percentage = 0.2):\n",
        "        \"\"\"Split the data by annotation dates\"\"\"\n",
        "\n",
        "        time_series_batch_split = (\n",
        "            train_sequences\n",
        "            .dropna(subset=\"first_release\")\n",
        "            .sort_values(\"first_release\")\n",
        "            .groupby(\"first_release\")[[\"EntryID\"]].count()\n",
        "            .rename(columns={\"EntryID\": \"n_released\"})\n",
        "            .assign(\n",
        "                cum_pct=lambda df: df.cumsum() / df.sum(),\n",
        "                tss_train=lambda df: df.cum_pct <= train_percentage,\n",
        "                tss_val=lambda df: (train_percentage < df.cum_pct) & (df.cum_pct <= train_percentage + val_percentage)\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return (\n",
        "            train_sequences\n",
        "            .merge(time_series_batch_split[[\"tss_train\", \"tss_val\"]],\n",
        "                   left_on=\"first_release\", right_index=True, how=\"left\")\n",
        "        )\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def split_X_data(\n",
        "            train_index: Sequence[int],\n",
        "            val_index: Sequence[int],\n",
        "            embeddings: Sequence[np.array],\n",
        "        ) -> Tuple[list[np.array], list[np.array]]:\n",
        "\n",
        "        X_trains = []\n",
        "        X_vals = []\n",
        "        for embedding in embeddings:\n",
        "            X_train, X_val = embedding[train_index], embedding[val_index]\n",
        "            X_trains.append(X_train)\n",
        "            X_vals.append(X_val)\n",
        "\n",
        "        return X_trains, X_vals\n",
        "\n",
        "    @staticmethod\n",
        "    def split_y_data(train_index: Sequence[int], val_index: Sequence[int], Y: np.array):\n",
        "        return Y[train_index], Y[val_index]\n",
        "\n",
        "\n",
        "    def check_shapes(self) -> None:\n",
        "        print(f\"{self.Y.shape = }\")\n",
        "        print(f\"{self.Y_labels.shape = }\")\n",
        "\n",
        "        print(\"embeddings:\")\n",
        "        for embed in self.embeddings:\n",
        "            print(embed.shape)\n",
        "\n",
        "        print(\"test_embeddings:\")\n",
        "        for embed in self.test_embeddings:\n",
        "            print(embed.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rSogD-WiURIo"
      },
      "outputs": [],
      "source": [
        "def postprocess_predictions_for_one_ontology(\n",
        "        predictions: NDArray[NDArray],          # Predictions\n",
        "        Y_labels: NDArray[str],                 # GO term string labels\n",
        "        protein_ids: Optional[Sequence[str]] = None,      # EntryIDs of proteins in test data\n",
        "        top_percent: float = 1.0,\n",
        "        dropzeros: bool = True,\n",
        "        verbose: bool = False,\n",
        "    ) -> pd.DataFrame:\n",
        "    \"\"\"Keep only top 5% predictions as the final predictions for the given ontology\"\"\"\n",
        "\n",
        "    # Prepare dataframe for submission\n",
        "    test_size = predictions.shape[0]\n",
        "    n_extracted_terms_from_current_ontology = predictions.shape[1]\n",
        "    if protein_ids is None:\n",
        "        protein_ids = np.arange(test_size)\n",
        "\n",
        "    submission_df = pd.DataFrame({\n",
        "        \"Protein Id\": np.repeat(protein_ids, n_extracted_terms_from_current_ontology),\n",
        "        \"GO Term Id\": np.tile(Y_labels, test_size),\n",
        "        \"Prediction\": predictions.ravel(),\n",
        "    })\n",
        "\n",
        "    # Select the top 5% rows based on 'Prediction'\n",
        "    top_rows = int(top_percent * submission_df.shape[0])\n",
        "    submission_df = submission_df.nlargest(top_rows, 'Prediction')\n",
        "\n",
        "    # Drop rows where 'Prediction' is equal or less than zero\n",
        "    if dropzeros:\n",
        "        epsilon = 0.0001\n",
        "        if verbose:\n",
        "            print('zeros dropped for', len(submission_df[submission_df['Prediction'] <= epsilon]), 'rows')\n",
        "        submission_df = submission_df[submission_df['Prediction'] > epsilon]\n",
        "\n",
        "    # Round to 4 decimals: Differences below 4 decimals are negligible\n",
        "    submission_df['Prediction'] = submission_df['Prediction'].round(4)\n",
        "\n",
        "    return submission_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "6FVhdPbuURIp",
        "outputId": "11e9da03-6845-4339-ef2e-8240854dce27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasets loaded\n",
            "Number of proteins with no CCO terms = 48882 out of 142246\n",
            "we retained 33387 proteins in training set where CCO terms are present\n",
            "we retained 11412 proteins in validation set where CCO terms are present\n",
            "we retained 11246 proteins in testing set where CCO terms are present\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-6c5c558e3504>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mCCO_ontology_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOntologyData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CCO\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mY_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCCO_ontology_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tss_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-6ed458fe66bd>\u001b[0m in \u001b[0;36mget_tss_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         return (\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data_by_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data_by_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data_by_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-6ed458fe66bd>\u001b[0m in \u001b[0;36m_get_data_by_indices\u001b[0;34m(self, filter_indices)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mesm2_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mesm2_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilter_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mpb_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpb_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilter_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mankh_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mankh_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilter_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mtaxa_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtaxa_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilter_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/memmap.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mmemmap\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mmap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/memmap.py\u001b[0m in \u001b[0;36m__array_finalize__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_mmap'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmay_share_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "CCO_ontology_data = OntologyData(\"CCO\", verbose=True)\n",
        "train_set, val_set, test_set, (Y_labels, weights) = CCO_ontology_data.get_tss_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH_bawReURIp"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "donVZOiuURIp"
      },
      "source": [
        "### Define Input Processing Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "w7oxHzL3URIp"
      },
      "outputs": [],
      "source": [
        "class ComposableLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"A base layer class that provides composition of sequential layers\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def compose_layers(layers: Iterable[tf.keras.layers.Layer], **kwargs) -> tf.keras.layers.Layer:\n",
        "        return tf.keras.layers.Lambda(\n",
        "            lambda x: functools.reduce(lambda tensor, layer: layer(tensor), layers, x),\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "\n",
        "    # def compose_layers(layers: Iterable[tf.keras.layers.Layer], **kwargs) -> tf.keras.layers.Layer:\n",
        "    #       return Sequential(layers, **kwargs)\n",
        "\n",
        "@register_keras_serializable()\n",
        "class BranchLayers(ComposableLayer):\n",
        "    \"\"\"Create an encoding branch/block to process a given embeddings\"\"\"\n",
        "\n",
        "    def __init__(self, l1_dim=300, l2_dim=600, dropout_rate=0.5, alpha=0.1, name_prefix=\"\", **kwargs):\n",
        "        super(BranchLayers, self).__init__(**kwargs)\n",
        "        self.l1_dim = l1_dim\n",
        "        self.l2_dim = l2_dim\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.alpha = alpha\n",
        "        self.prefix = f\"{name_prefix}_\" if name_prefix else \"\"\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"Create the weights and build the layers (after the input shape is known)\"\"\"\n",
        "        self.sequential_layers = self.compose_layers({\n",
        "            Dense(self.l1_dim, name=f'{self.prefix}dense_1'),\n",
        "            BatchNormalization(name=f'{self.prefix}batchnorm_1'),\n",
        "            LeakyReLU(negative_slope=self.alpha, name=f'{self.prefix}leakyrelu_1'),\n",
        "            #LeakyReLU(alpha=self.alpha, name=f'{self.prefix}leakyrelu_1'),\n",
        "            Dropout(self.dropout_rate, name=f'{self.prefix}dropout_1'),\n",
        "            Dense(self.l2_dim, name=f'{self.prefix}dense_2'),\n",
        "        })\n",
        "        super(BranchLayers, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.sequential_layers(inputs)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(BranchLayers, self).get_config()\n",
        "        config.update({\n",
        "            'l1_dim': self.l1_dim,\n",
        "            'l2_dim': self.l2_dim,\n",
        "            'dropout_rate': self.dropout_rate,\n",
        "            'alpha': self.alpha,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHX6jRXlURIp"
      },
      "source": [
        "### Define PROTGOAT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CfHmqu9DURIp"
      },
      "outputs": [],
      "source": [
        "@register_keras_serializable()\n",
        "class ProtgoatEnsembleBlock(ComposableLayer):\n",
        "    \"\"\"Create an ensemble block to merge all embeddings\"\"\"\n",
        "\n",
        "    def __init__(self, final_dim, **kwargs):\n",
        "        super(ProtgoatEnsembleBlock, self).__init__(**kwargs)\n",
        "        self.final_dim = final_dim\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"Create the weights and build the layers (after the input shape is known)\"\"\"\n",
        "        self.sequential_layers = self.compose_layers({\n",
        "            BatchNormalization(name = 'combined_batchnorm_1'),\n",
        "            Dense(self.final_dim, name='combined_dense_1', activation='relu'),\n",
        "        })\n",
        "        super(ProtgoatEnsembleBlock, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.sequential_layers(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_struct_PROTGOAT(\n",
        "        t5_train: np.array,\n",
        "        esm1_train: np.array,\n",
        "        esm2_train: np.array,\n",
        "        pb_train: np.array,\n",
        "        ankh_train: np.array,\n",
        "        taxa_train: np.array,\n",
        "        train_structures: np.array,\n",
        "        model_params: ModelParameters,\n",
        "        output_shape: int,\n",
        "    ):\n",
        "\n",
        "    # Define the inputs\n",
        "    t5_in = Input(shape=(t5_train.shape[1],), name = 't5_input')\n",
        "    esm1_in = Input(shape=(esm1_train.shape[1],), name = 'esm1_input')\n",
        "    esm2_in = Input(shape=(esm2_train.shape[1],), name = 'esm2_input')\n",
        "    pb_in = Input(shape=(pb_train.shape[1],), name = 'pb_input')\n",
        "    ankh_in = Input(shape=(ankh_train.shape[1],), name = 'ankh_input')\n",
        "    taxa_in = Input(shape=(taxa_train.shape[1],), name = 'taxa_input')\n",
        "    struct_in = Input(shape=(train_structures.shape[1],),name='struct_embed')\n",
        "\n",
        "\n",
        "    # Define the branches for each inputs\n",
        "    t5_branch = BranchLayers(**model_params.branch_kwargs, name_prefix=\"t5\")\n",
        "    esm1_branch = BranchLayers(**model_params.branch_kwargs, name_prefix=\"esm1\")\n",
        "    esm2_branch = BranchLayers(**model_params.branch_kwargs, name_prefix=\"esm2\")\n",
        "    pb_branch = BranchLayers(**model_params.branch_kwargs, name_prefix=\"pb\")\n",
        "    ankh_branch = BranchLayers(**model_params.branch_kwargs, name_prefix=\"ankh\")\n",
        "    taxa_branch = BranchLayers(**model_params.branch_kwargs, name_prefix=\"taxa\")\n",
        "    # ad line\n",
        "    struct_branch=BranchLayers(**model_params.branch_kwargs, name_prefix=\"struct\")\n",
        "\n",
        "    # Defined the ensembling block\n",
        "    ensemble = ProtgoatEnsembleBlock(model_params.final_dim)\n",
        "\n",
        "    # Build the branches' weights\n",
        "    t5_branch.build(input_shape=(t5_train.shape[1],))\n",
        "    esm1_branch.build(input_shape=(esm1_train.shape[1],))\n",
        "    esm2_branch.build(input_shape=(esm2_train.shape[1],))\n",
        "    pb_branch.build(input_shape=(pb_train.shape[1],))\n",
        "    ankh_branch.build(input_shape=(ankh_train.shape[1],))\n",
        "    taxa_branch.build(input_shape=(taxa_train.shape[1],))\n",
        "    # add line\n",
        "    struct_branch.build(input_shape=(train_structures.shape[1],))\n",
        "\n",
        "    # Build the ensemble' weights\n",
        "    combined_shape = sum(data.shape[1] for data in [t5_train, esm1_train, esm2_train, pb_train, ankh_train, taxa_train])\n",
        "    ensemble.build(input_shape=(combined_shape,))\n",
        "\n",
        "    # Feed the inputs into the branches\n",
        "    t5_branch = t5_branch(t5_in)\n",
        "    esm1_branch = esm1_branch(esm1_in)\n",
        "    esm2_branch = esm2_branch(esm2_in)\n",
        "    pb_branch = pb_branch(pb_in)\n",
        "    ankh_branch = ankh_branch(ankh_in)\n",
        "    taxa_branch = taxa_branch(taxa_in)\n",
        "    struct_branch=struct_branch(struct_in)\n",
        "\n",
        "    # Merge the branches & output predictions\n",
        "    concatenated = Concatenate()([t5_branch, esm1_branch, esm2_branch, pb_branch, ankh_branch, taxa_branch])\n",
        "    ensembled = ensemble(concatenated)\n",
        "    final_embedding = Concatenate()([ensembled, struct_branch])\n",
        "\n",
        "\n",
        "    last_hidden_state=BranchLayers(**model_params.branch_kwargs, name_prefix=\"final_mlp\")(final_embedding)\n",
        "\n",
        "\n",
        "\n",
        "    output = Dense(output_shape, activation='sigmoid', name='final_output')(last_hidden_state)\n",
        "\n",
        "\n",
        "    # print(\"Shape after t5_branch:\", t5_branch.shape)\n",
        "    # print(\"Shape after concatenation:\", concatenated.shape)\n",
        "    # print(\"Shape after final mlp branch:\", last_hidden_state.shape)\n",
        "\n",
        "    model = Model(inputs=[t5_in, esm1_in, esm2_in, pb_in, ankh_in, taxa_in, struct_in], outputs=output)\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "    # # Create the model\n",
        "    # #return Model(inputs=[t5_in, esm1_in, esm2_in, pb_in, ankh_in, taxa_in,struct_in],\n",
        "    #              outputs=output)"
      ],
      "metadata": {
        "id": "kZTURM9cd4lQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TzWhFGIURIq"
      },
      "outputs": [],
      "source": [
        "# def create_PROTGOAT(\n",
        "#         t5_train: np.array,\n",
        "#         esm1_train: np.array,\n",
        "#         esm2_train: np.array,\n",
        "#         pb_train: np.array,\n",
        "#         ankh_train: np.array,\n",
        "#         taxa_train: np.array,\n",
        "#         struct_train:np.array,\n",
        "#         model_params: ModelParameters,\n",
        "#         output_shape: int,\n",
        "#     ):\n",
        "\n",
        "#     # Define the inputs\n",
        "#     t5_in = Input(shape=(t5_train.shape[1],), name = 't5_input')\n",
        "#     esm1_in = Input(shape=(esm1_train.shape[1],), name = 'esm1_input')\n",
        "#     esm2_in = Input(shape=(esm2_train.shape[1],), name = 'esm2_input')\n",
        "#     pb_in = Input(shape=(pb_train.shape[1],), name = 'pb_input')\n",
        "#     ankh_in = Input(shape=(ankh_train.shape[1],), name = 'ankh_input')\n",
        "#     taxa_in = Input(shape=(taxa_train.shape[1],), name = 'taxa_input')\n",
        "\n",
        "#     # Define the branches for each inputs\n",
        "#     t5_branch = BranchLayers(**model_params.branch_kwargs, name_prefix=\"t5\")\n",
        "#     esm1_branch = BranchLayers(**model_params.branch_kwargs, name_prefix=\"esm1\")\n",
        "#     esm2_branch = BranchLayers(**model_params.branch_kwargs, name_prefix=\"esm2\")\n",
        "#     pb_branch = BranchLayers(**model_params.branch_kwargs, name_prefix=\"pb\")\n",
        "#     ankh_branch = BranchLayers(**model_params.branch_kwargs, name_prefix=\"ankh\")\n",
        "#     taxa_branch = BranchLayers(**model_params.branch_kwargs, name_prefix=\"taxa\")\n",
        "\n",
        "#     # Defined the ensembling block\n",
        "#     ensemble = ProtgoatEnsembleBlock(model_params.final_dim)\n",
        "\n",
        "#     # Build the branches' weights\n",
        "#     t5_branch.build(input_shape=(t5_train.shape[1],))\n",
        "#     esm1_branch.build(input_shape=(esm1_train.shape[1],))\n",
        "#     esm2_branch.build(input_shape=(esm2_train.shape[1],))\n",
        "#     pb_branch.build(input_shape=(pb_train.shape[1],))\n",
        "#     ankh_branch.build(input_shape=(ankh_train.shape[1],))\n",
        "#     taxa_branch.build(input_shape=(taxa_train.shape[1],))\n",
        "\n",
        "#     # Build the ensemble' weights\n",
        "#     combined_shape = sum(data.shape[1] for data in [t5_train, esm1_train, esm2_train, pb_train, ankh_train, taxa_train])\n",
        "#     ensemble.build(input_shape=(combined_shape,))\n",
        "\n",
        "#     # Feed the inputs into the branches\n",
        "#     t5_branch = t5_branch(t5_in)\n",
        "#     esm1_branch = esm1_branch(esm1_in)\n",
        "#     esm2_branch = esm2_branch(esm2_in)\n",
        "#     pb_branch = pb_branch(pb_in)\n",
        "#     ankh_branch = ankh_branch(ankh_in)\n",
        "#     taxa_branch = taxa_branch(taxa_in)\n",
        "\n",
        "#     # Merge the branches & output predictions\n",
        "#     concatenated = Concatenate()([t5_branch, esm1_branch, esm2_branch, pb_branch, ankh_branch, taxa_branch])\n",
        "#     ensembled = ensemble(concatenated)\n",
        "#     output = Dense(output_shape, activation='sigmoid', name='final_output')(ensembled)\n",
        "\n",
        "#     # Create the model\n",
        "#     return Model(inputs=[t5_in, esm1_in, esm2_in, pb_in, ankh_in, taxa_in],\n",
        "#                  outputs=output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMOFqT_DURIq"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKM0UT9CURIq"
      },
      "source": [
        "### Training Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6-xHl4gXURIq"
      },
      "outputs": [],
      "source": [
        "#lr scheduling\n",
        "def lr_schedule(epoch: int, lr: float) -> float:\n",
        "    if epoch > 0 and epoch % 10 == 0:\n",
        "        lr = lr * 0.5\n",
        "    return lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0Smtz-dNURIq"
      },
      "outputs": [],
      "source": [
        "def train_and_save_one_model(model, X_trains, y_train, X_vals, y_val, weights,\n",
        "                             model_savepath, logger_savepath, train_params, lr_schedule=lr_schedule,\n",
        "                             lr_verbose=0, train_verbose=0, checkpoint_verbose=0) -> None:\n",
        "\n",
        "    print(f\"Training: {model_savepath}\")\n",
        "\n",
        "    # Set seed\n",
        "    set_random_seed(train_params.seed)\n",
        "\n",
        "    # Define callbacks\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=train_params.patience, verbose=1)\n",
        "    checkpoint_loss = ModelCheckpoint(\n",
        "        filepath = model_savepath,\n",
        "        monitor = 'val_loss',\n",
        "        verbose = checkpoint_verbose,\n",
        "        save_best_only = True,\n",
        "        save_weights_only = False,\n",
        "        mode = 'min',\n",
        "    )\n",
        "    csv_logger = CSVLogger(logger_savepath)\n",
        "    lr_callback = LearningRateScheduler(lr_schedule, verbose=lr_verbose)\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer = Adam(learning_rate=train_params.learning_rate),\n",
        "                    loss = 'binary_crossentropy',\n",
        "                    metrics = ['binary_accuracy', tf.keras.metrics.AUC()])\n",
        "\n",
        "    # Train & save model\n",
        "    history = model.fit(\n",
        "        X_trains, y_train,\n",
        "        validation_data=(X_vals, y_val),\n",
        "        class_weight=weights,\n",
        "        epochs=train_params.n_epochs, batch_size=train_params.batch_size,\n",
        "        callbacks=[checkpoint_loss, csv_logger, lr_callback, early_stopping],\n",
        "        verbose=train_verbose,\n",
        "    )\n",
        "\n",
        "    # Code health\n",
        "    K.clear_session()\n",
        "    _ = gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "D7vkmmySURIq"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model_path: Path, test_embeddings: list):\n",
        "    model = load_model(model_path)\n",
        "    predicted_outputs = model.predict(test_embeddings)\n",
        "    K.clear_session()\n",
        "    _ = gc.collect()\n",
        "    return predicted_outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfj-LeTwURIq"
      },
      "source": [
        "### Define Submission Pipeline (for CAFA5 Kaggle competition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "B2x9dvd-URIr"
      },
      "outputs": [],
      "source": [
        "def get_mean_predictions(model_name: str, ontology: str, test_embeddings: list, rand_seed: int = 0):\n",
        "    predictions = []\n",
        "    for fold_ct in [1,2,3,4,5]:\n",
        "        # Load the model\n",
        "        model_filename = MODEL_FILENAME_TEMPLATE.format(model_name=model_name, ontology=ontology,\n",
        "                                                        fold_ct=fold_ct, rand_seed=rand_seed)\n",
        "        model = load_model(MODEL_SAVE_DIR / f\"{model_filename}.keras\")\n",
        "        # Make predictions for this fold\n",
        "        predicted_outputs = model.predict(test_embeddings)\n",
        "        # Record the fold predictions\n",
        "        predictions.append(predicted_outputs)\n",
        "\n",
        "        K.clear_session()\n",
        "        _ = gc.collect()\n",
        "\n",
        "    # Average over the folds to get mean prediction scores\n",
        "    return np.mean(predictions, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6AIcyl9HURIr"
      },
      "outputs": [],
      "source": [
        "def pipeline_for_one_ontology(\n",
        "        model_name: str,\n",
        "        create_model: Callable,\n",
        "        ontology_data: OntologyData,\n",
        "        train_params: TrainingParameters = TrainingParameters(),\n",
        "        model_params: ModelParameters = ModelParameters(),\n",
        "        cv_params: CrossValidationParameters = CrossValidationParameters(),\n",
        "        cv_splitter_class: _BaseKFold = KFold,\n",
        "        top_percent: float = 0.05,\n",
        "        test_labels: Iterable = np.load(os.path.join(EMBEDDING_DIR, 't5_test_labels_sorted.npy')), # For submission for CAFA test set\n",
        "        train_verbose: int = 0,\n",
        "        lr_verbose: int = 0,\n",
        "        checkpoint_verbose: int = 0,\n",
        "    ):\n",
        "    \"\"\"A huge function that gets and splits data, train models\"\"\"\n",
        "\n",
        "    # 1) Get all relevant data for a specified ontology\n",
        "    embeddings, test_embeddings, (Y, Y_labels, weights) = ontology_data.get_data()\n",
        "    ontology = ontology_data.ontology\n",
        "\n",
        "    # 2) Train & Save 5 models in each fold\n",
        "    cv_splitter = cv_splitter_class(**cv_params._asdict())\n",
        "    split_enumerator = enumerate(cv_splitter.split(embeddings[0]), start=1)\n",
        "    for fold_ct, (train_index, val_index) in tqdm(split_enumerator):\n",
        "        # Split the embeddings and labels into train and test set\n",
        "        X_trains, X_vals = ontology_data.split_X_data(train_index, val_index, embeddings)\n",
        "        y_train, y_val = ontology_data.split_y_data(train_index, val_index, Y)\n",
        "        # Create the model\n",
        "        model = create_model(*X_trains, model_params, ontology_data.n_terms) # the number of GO terms considered for this ontology\n",
        "        # Define save paths\n",
        "        save_name = MODEL_FILENAME_TEMPLATE.format(model_name=model_name, ontology=ontology,\n",
        "                                                   fold_ct=fold_ct, rand_seed=train_params.seed)\n",
        "        model_savepath: Path = MODEL_SAVE_DIR / f\"{save_name}.keras\"\n",
        "        logger_savepath: Path = MODEL_LOGS_SAVE_DIR / f\"{save_name}.csv\"\n",
        "        # Train & Save the model\n",
        "        train_and_save_one_model(model, X_trains, y_train, X_vals, y_val, weights,\n",
        "                                 model_savepath, logger_savepath, train_params,\n",
        "                                 train_verbose=train_verbose, lr_verbose=lr_verbose,\n",
        "                                 checkpoint_verbose=checkpoint_verbose)\n",
        "\n",
        "    # 3) Get predictions for this ontology (with some post-processing)\n",
        "    average_predictions = get_mean_predictions(model_name, ontology, test_embeddings)\n",
        "    submission_df = postprocess_predictions_for_one_ontology(\n",
        "        average_predictions, Y_labels, test_labels,\n",
        "        top_percent=top_percent, # Only select the top 5% GO terms in prediction scores\n",
        "    )\n",
        "    # 4) Save predictions to file\n",
        "    submission_filename = ONTOLOGY_SUBMISSION_TEMPLATE.format(ontology=ontology, model_name=model_name)\n",
        "    submission_df.to_csv(PREDICTION_DIR / submission_filename, header=False, index=False, sep=\"\\t\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "8VvbmL89URIr"
      },
      "outputs": [],
      "source": [
        "def prepare_final_submission(model_name: str) -> pd.DataFrame:\n",
        "    \"\"\"Merge the predictions from all three ontologies & write to file\"\"\"\n",
        "\n",
        "    # Specify the file paths of the TSV files to concatenate\n",
        "    ontology_submission_filepaths = [\n",
        "        os.path.join(\n",
        "            PREDICTION_DIR,\n",
        "            ONTOLOGY_SUBMISSION_TEMPLATE.format(ontology=ontology, model_name=model_name))\n",
        "        for ontology in BRANCH_ABBR.values()]\n",
        "\n",
        "    # Read & Concatenate the DataFrames\n",
        "    concatenated_df = pd.concat([\n",
        "        pd.read_csv(filepath, sep='\\t', names=[\"Protein Id\", \"GO Term Id\", \"Prediction\"])\n",
        "        for filepath in ontology_submission_filepaths\n",
        "    ], ignore_index=True).sort_values([\"Protein Id\", \"GO Term Id\"])\n",
        "\n",
        "    # Save the concatenated DataFrame to a new TSV file\n",
        "    concatenated_df.to_csv(SUBMISSION_DIR / f\"{model_name}.tsv\", sep='\\t', header=False, index=False)\n",
        "\n",
        "    return concatenated_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "k9C5QaMlURIr"
      },
      "outputs": [],
      "source": [
        "def pipeline_for_all_ontologies(create_model: Callable, model_name: str, load_data_verbose: bool = False, **kwargs):\n",
        "\n",
        "    # Train model on all three ontologies (get data, save models, write results, prepare submissions)\n",
        "    ontologies = BRANCH_ABBR.values()\n",
        "    for ontology in ontologies:\n",
        "        # Get data for this ontology\n",
        "        ontology_data = OntologyData(ontology, verbose=load_data_verbose)\n",
        "        # Feed data into pipeline\n",
        "        pipeline_for_one_ontology(\n",
        "            model_name = model_name,\n",
        "            create_model = create_model,\n",
        "            ontology_data = ontology_data,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "    # Get final submission: Merge all predictions from three ontolotgies & Write to file\n",
        "    return prepare_final_submission(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7plL2BlURIr"
      },
      "source": [
        "### Define Cross-validation Pipeline (for Final Project)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "49Uu11WtURIr"
      },
      "outputs": [],
      "source": [
        "def cv_pipeline_for_one_ontology(\n",
        "        model_name: str,\n",
        "        create_model: Callable,\n",
        "        ontology_data: OntologyData,\n",
        "        train_params: TrainingParameters = TrainingParameters(),\n",
        "        model_params: ModelParameters = ModelParameters(),\n",
        "        cv_params: CrossValidationParameters = CrossValidationParameters(),\n",
        "        cv_splitter_class: _BaseKFold = KFold,\n",
        "        top_percent: float = 0.05,\n",
        "        train_verbose: int = 0,\n",
        "        lr_verbose: int = 0,\n",
        "        checkpoint_verbose: int = 0,\n",
        "    ) -> list[NDArray]:\n",
        "    \"\"\"A huge function that gets and splits data, train models, and gather predictions\"\"\"\n",
        "\n",
        "    # 1) Get all relevant data for a specified ontology\n",
        "    cv_fold_data: list[tuple] = ontology_data.get_cv_split_data(cv_params, cv_splitter_class)\n",
        "    ontology = ontology_data.ontology\n",
        "    weights = ontology_data.weights\n",
        "    Y_labels = ontology_data.Y_labels\n",
        "\n",
        "\n",
        "    # 2) Train & Save models in each fold\n",
        "    y_test_list = []\n",
        "    for fold_ct, X_trains, y_train, X_vals, y_val, X_tests, y_test in tqdm(cv_fold_data):\n",
        "        print(f\"Fold: {fold_ct}\")\n",
        "\n",
        "        # Create the model\n",
        "        model = create_model(*X_trains, model_params, ontology_data.n_terms)\n",
        "\n",
        "        # Define save paths\n",
        "        save_name = MODEL_CV_FILENAME_TEMPLATE.format(model_name=model_name, ontology=ontology,\n",
        "                                                      fold_ct=fold_ct, rand_seed=train_params.seed)\n",
        "        model_savepath: Path = MODEL_SAVE_DIR / f\"{save_name}.keras\"\n",
        "        logger_savepath: Path = MODEL_LOGS_SAVE_DIR / f\"{save_name}.csv\"\n",
        "\n",
        "        # Train & Save the model\n",
        "        train_and_save_one_model(model, X_trains, y_train, X_vals, y_val, weights,\n",
        "                                 model_savepath, logger_savepath, train_params,\n",
        "                                 train_verbose=train_verbose, lr_verbose=lr_verbose,\n",
        "                                 checkpoint_verbose=checkpoint_verbose)\n",
        "\n",
        "\n",
        "        # 3) Get predictions for this ontology (with some post-processing)\n",
        "        predictions: np.ndarray = get_predictions(model_savepath, X_tests)\n",
        "        fold_predictions: pd.DataFrame = postprocess_predictions_for_one_ontology(\n",
        "            predictions, Y_labels, y_test,\n",
        "            top_percent=top_percent, # Only select the top 5% GO terms in prediction scores\n",
        "        )\n",
        "\n",
        "        # 4) Save fold predictions to file\n",
        "        fold_prediction_filename = ONTOLOGY_FOLD_PREDICTION_TEMPLATE.format(ontology=ontology, model_name=model_name, fold_ct=fold_ct)\n",
        "        fold_predictions.to_csv(PREDICTION_DIR / fold_prediction_filename, header=False, index=False, sep=\"\\t\")\n",
        "\n",
        "        # 5) Record the ground truth for each fold\n",
        "        y_test_list.append(y_test)\n",
        "\n",
        "    return y_test_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "LAsFF2U8URIw"
      },
      "outputs": [],
      "source": [
        "def merge_ontology_fold_predictions(model_name: str, write_to_file: bool = True) -> pd.DataFrame:\n",
        "    \"\"\"Merge the fold predictions from all three ontologies & write to file\"\"\"\n",
        "\n",
        "    all_fold_concatenated_df = []\n",
        "    for fold_ct in (1,2,3,4,5):\n",
        "\n",
        "        # Specify the file paths of the TSV files to concatenate\n",
        "        ontology_submission_filepaths = [\n",
        "            os.path.join(\n",
        "                PREDICTION_DIR,\n",
        "                ONTOLOGY_FOLD_PREDICTION_TEMPLATE.format(ontology=ontology, model_name=model_name, fold_ct=fold_ct))\n",
        "            for ontology in BRANCH_ABBR.values()]\n",
        "\n",
        "        # Read & Concatenate the DataFrames\n",
        "        concatenated_df = (\n",
        "            pd.concat([\n",
        "                pd.read_csv(filepath, sep='\\t', header=None, names=[\"Protein Id\", \"GO Term Id\", \"Prediction\"])\n",
        "                for filepath in ontology_submission_filepaths\n",
        "            ], ignore_index=True)\n",
        "            .sort_values([\"Protein Id\", \"GO Term Id\"])\n",
        "            .assign(fold=fold_ct)\n",
        "        )\n",
        "        all_fold_concatenated_df.append(concatenated_df)\n",
        "\n",
        "        # Save the concatenated DataFrame to a new TSV file\n",
        "        if write_to_file:\n",
        "            concatenated_df.to_csv(SUBMISSION_DIR / f\"{model_name}_cv.tsv\", sep='\\t', header=False, index=False)\n",
        "\n",
        "    return pd.concat(all_fold_concatenated_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "FkQnnvYEURIw"
      },
      "outputs": [],
      "source": [
        "def cv_pipeline_for_all_ontologies(create_model: Callable, model_name: str, load_data_verbose: bool = False, **kwargs):\n",
        "\n",
        "    # Train model on all three ontologies (get data, save models, write results, prepare submissions)\n",
        "    ontologies = BRANCH_ABBR.values()\n",
        "    for ontology in ontologies:\n",
        "        # Get data for this ontology\n",
        "        ontology_data = OntologyData(ontology, verbose=load_data_verbose)\n",
        "        # Feed data into pipeline & Save results to files\n",
        "        cv_pipeline_for_one_ontology(\n",
        "            model_name = model_name,\n",
        "            create_model = create_model,\n",
        "            ontology_data = ontology_data,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "    # Merge all cv predictions from three ontologies & Write to file\n",
        "    return merge_ontology_fold_predictions(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_kOAoxqURIw"
      },
      "source": [
        "### Define Time Series Split Pipeline (for Final Project)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "oUejU3bXURIx"
      },
      "outputs": [],
      "source": [
        "def tss_pipeline_for_one_ontology(\n",
        "        model_name: str,\n",
        "        create_model: Callable,\n",
        "        ontology_data: OntologyData,\n",
        "        train_params: TrainingParameters = TrainingParameters(),\n",
        "        model_params: ModelParameters = ModelParameters(),\n",
        "        top_percent: float = 0.05,\n",
        "        train_verbose: int = 0,\n",
        "        lr_verbose: int = 0,\n",
        "        checkpoint_verbose: int = 0,\n",
        "    ) -> list[NDArray]:\n",
        "    \"\"\"A huge function that gets and splits data, train models, and gather predictions\"\"\"\n",
        "\n",
        "    # 1) Split the ontology data by Time Series Split (TSS)\n",
        "    train_set, val_set, test_set, (GO_labels, weights) = ontology_data.get_tss_data()\n",
        "\n",
        "    X_trains, X_labels_train, y_train = train_set\n",
        "    X_vals, X_labels_val, y_val = val_set\n",
        "    X_tests, X_labels_test, y_test = test_set\n",
        "\n",
        "    # 2) Train & Save one model for one ontology\n",
        "\n",
        "    ## Create the model\n",
        "    model = create_model(*X_trains, model_params, ontology_data.n_terms)\n",
        "\n",
        "    ## Define save paths\n",
        "    save_name = MODEL_TSS_FILENAME_TEMPLATE.format(model_name=model_name, ontology=ontology_data.ontology, rand_seed=train_params.seed)\n",
        "    model_savepath: Path = MODEL_SAVE_DIR / f\"{save_name}.keras\"\n",
        "    logger_savepath: Path = MODEL_LOGS_SAVE_DIR / f\"{save_name}.csv\"\n",
        "\n",
        "    ## Train & Save the model\n",
        "    train_and_save_one_model(model, X_trains, y_train, X_vals, y_val, weights,\n",
        "                                model_savepath, logger_savepath, train_params,\n",
        "                                train_verbose=train_verbose, lr_verbose=lr_verbose,\n",
        "                                checkpoint_verbose=checkpoint_verbose)\n",
        "\n",
        "    # 3) Get predictions for this ontology (with some post-processing)\n",
        "    predictions: np.ndarray = get_predictions(model_savepath, X_tests)\n",
        "    tss_predictions: pd.DataFrame = postprocess_predictions_for_one_ontology(\n",
        "        predictions, GO_labels, X_labels_test,\n",
        "        top_percent=top_percent, # Default select only the top 5% GO terms in prediction scores\n",
        "    )\n",
        "\n",
        "    # 4) Save tss predictions to file\n",
        "    tss_prediction_filename = ONTOLOGY_TSS_PREDICTION_TEMPLATE.format(ontology=ontology_data.ontology, model_name=model_name)\n",
        "    tss_predictions.to_csv(PREDICTION_DIR / tss_prediction_filename, header=False, index=False, sep=\"\\t\")\n",
        "\n",
        "    return X_labels_test, y_test, GO_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mnd_CQszURIx"
      },
      "outputs": [],
      "source": [
        "# ground_truths = pd.DataFrame(y_test, columns=Y_labels, index=X_labels_test)\n",
        "# ground_truths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "gXxdIhyxURIx"
      },
      "outputs": [],
      "source": [
        "def concat_tss_ontology_predictions(model_name: str, write_to_file: bool = True) -> pd.DataFrame:\n",
        "\n",
        "    # Specify the file paths of the TSV files to concatenate\n",
        "    ontology_prediction_filepaths = [\n",
        "        os.path.join(\n",
        "            PREDICTION_DIR,\n",
        "            ONTOLOGY_TSS_PREDICTION_TEMPLATE.format(ontology=ontology, model_name=model_name))\n",
        "        for ontology in BRANCH_ABBR.values()\n",
        "    ]\n",
        "\n",
        "    # Read & Concatenate the DataFrames\n",
        "    concatenated_df = (\n",
        "        pd.concat([\n",
        "            pd.read_csv(filepath, sep='\\t', header=None, names=[\"Protein Id\", \"GO Term Id\", \"Prediction\"])\n",
        "            for filepath in ontology_prediction_filepaths\n",
        "        ], ignore_index=True)\n",
        "        .sort_values([\"Protein Id\", \"GO Term Id\"])\n",
        "    )\n",
        "\n",
        "    # Save the concatenated DataFrame to a new TSV file\n",
        "    if write_to_file:\n",
        "        concatenated_df.to_csv(SUBMISSION_DIR / f\"{model_name}_tss.tsv\", sep='\\t', header=False, index=False)\n",
        "\n",
        "    return concatenated_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkY19kJwURIx"
      },
      "outputs": [],
      "source": [
        "# concatenated_df.drop_duplicates()#.pivot(index='Protein Id', columns='GO Term Id', values='Prediction').stack()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWGSa3pFURIx"
      },
      "outputs": [],
      "source": [
        "# for ontology in ontologies:\n",
        "#     ontology_prediction_filename = ONTOLOGY_TSS_PREDICTION_TEMPLATE.format(ontology=ontology_data.ontology, model_name=\"protgoat\")\n",
        "#     ontology_predictions = pd.read_csv(PREDICTION_DIR / ontology_prediction_filename, header=None, sep=\"\\t\")\n",
        "#     display(ontology_predictions)\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "08Na4RwvURIx"
      },
      "outputs": [],
      "source": [
        "def tss_pipeline_for_all_ontologies(create_model: Callable, model_name: str, load_data_verbose: bool = False, **kwargs):\n",
        "    # Train model on all three ontologies (get data, save models, write results, prepare submissions)\n",
        "    ontologies = BRANCH_ABBR.values()\n",
        "    ground_truths = []\n",
        "    for ontology in ontologies:\n",
        "        # 1) Load data for this ontology\n",
        "        ontology_data = OntologyData(ontology, verbose=False)\n",
        "\n",
        "        # 2) Feed data into pipeline & Save results to files\n",
        "        X_labels_test, y_test, GO_labels = tss_pipeline_for_one_ontology(\n",
        "            model_name = model_name,\n",
        "            create_model = create_model,\n",
        "            ontology_data = ontology_data,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        # Record ground truth for this ontology\n",
        "        ground_truths.append(pd.DataFrame(y_test, columns=GO_labels, index=X_labels_test))\n",
        "\n",
        "    # Concatenate predictions from three ontologies\n",
        "    concat_pred_df = concat_tss_ontology_predictions(model_name, write_to_file = True)\n",
        "\n",
        "    return concat_pred_df, ground_truths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHVGNXxcURIy"
      },
      "source": [
        "### Run pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LpfKmQJxURIy",
        "outputId": "a5813fb9-62a0-4a44-ab35-f63bd4f3f5fd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ t5_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ esm1_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ esm2_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2560\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ pb_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ankh_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ taxa_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ t5_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ esm1_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ esm2_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ pb_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ ankh_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ taxa_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2100\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ branch_layers[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ branch_layers_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                           │                        │                │ branch_layers_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                           │                        │                │ branch_layers_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                           │                        │                │ branch_layers_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                           │                        │                │ branch_layers_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ struct_embed (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21592\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ protgoat_ensemble_block   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mProtgoatEnsembleBlock\u001b[0m)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ struct_embed[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1400\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ protgoat_ensemble_blo… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ branch_layers_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ final_output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1500\u001b[0m)           │        \u001b[38;5;34m901,500\u001b[0m │ branch_layers_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ t5_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ esm1_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ esm2_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2560</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ pb_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ankh_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ taxa_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ t5_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ esm1_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ esm2_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ pb_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ankh_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ taxa_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2100</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ branch_layers[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ branch_layers_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                           │                        │                │ branch_layers_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                           │                        │                │ branch_layers_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                           │                        │                │ branch_layers_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                           │                        │                │ branch_layers_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ struct_embed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21592</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ protgoat_ensemble_block   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ProtgoatEnsembleBlock</span>)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ struct_embed[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1400</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ protgoat_ensemble_blo… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ branch_layers_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ final_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">901,500</span> │ branch_layers_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m901,500\u001b[0m (3.44 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">901,500</span> (3.44 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m901,500\u001b[0m (3.44 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">901,500</span> (3.44 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Training: models/struct_protgoat_BPO_r0_tss.keras\n",
            "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ t5_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ esm1_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ esm2_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2560\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ pb_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ankh_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ taxa_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ t5_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ esm1_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ esm2_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ pb_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ ankh_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ taxa_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2700\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ branch_layers[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ branch_layers_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                           │                        │                │ branch_layers_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                           │                        │                │ branch_layers_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                           │                        │                │ branch_layers_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                           │                        │                │ branch_layers_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ struct_embed (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21592\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ protgoat_ensemble_block   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mProtgoatEnsembleBlock\u001b[0m)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ struct_embed[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1400\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ protgoat_ensemble_blo… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ branch_layers_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ final_output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m)            │        \u001b[38;5;34m480,800\u001b[0m │ branch_layers_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ t5_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ esm1_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ esm2_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2560</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ pb_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ankh_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ taxa_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ t5_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ esm1_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ esm2_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ pb_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ankh_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ taxa_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2700</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ branch_layers[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ branch_layers_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                           │                        │                │ branch_layers_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                           │                        │                │ branch_layers_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                           │                        │                │ branch_layers_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                           │                        │                │ branch_layers_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ struct_embed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21592</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ protgoat_ensemble_block   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ProtgoatEnsembleBlock</span>)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ struct_embed[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1400</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ protgoat_ensemble_blo… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ branch_layers_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ final_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">480,800</span> │ branch_layers_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m480,800\u001b[0m (1.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">480,800</span> (1.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m480,800\u001b[0m (1.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">480,800</span> (1.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Training: models/struct_protgoat_CCO_r0_tss.keras\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ t5_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ esm1_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ esm2_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2560\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ pb_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ankh_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ taxa_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ t5_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ esm1_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ esm2_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ pb_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ ankh_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ taxa_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3000\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ branch_layers[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ branch_layers_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                           │                        │                │ branch_layers_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                           │                        │                │ branch_layers_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                           │                        │                │ branch_layers_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                           │                        │                │ branch_layers_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ struct_embed (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21592\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ protgoat_ensemble_block   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mProtgoatEnsembleBlock\u001b[0m)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ struct_embed[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1100\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ protgoat_ensemble_blo… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ branch_layers_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBranchLayers\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ final_output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m)            │        \u001b[38;5;34m480,800\u001b[0m │ branch_layers_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ t5_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ esm1_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ esm2_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2560</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ pb_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ankh_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ taxa_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ t5_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ esm1_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ esm2_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ pb_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ankh_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ taxa_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3000</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ branch_layers[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ branch_layers_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                           │                        │                │ branch_layers_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                           │                        │                │ branch_layers_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                           │                        │                │ branch_layers_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                           │                        │                │ branch_layers_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ struct_embed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21592</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ protgoat_ensemble_block   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ProtgoatEnsembleBlock</span>)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ struct_embed[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1100</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ protgoat_ensemble_blo… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ branch_layers_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ branch_layers_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BranchLayers</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ final_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">480,800</span> │ branch_layers_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m480,800\u001b[0m (1.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">480,800</span> (1.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m480,800\u001b[0m (1.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">480,800</span> (1.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Training: models/struct_protgoat_MFO_r0_tss.keras\n",
            "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n"
          ]
        }
      ],
      "source": [
        "# Time series split!!!\n",
        "concat_pred_df, ground_truths = tss_pipeline_for_all_ontologies(\n",
        "    create_struct_PROTGOAT,\n",
        "    \"struct_protgoat\",\n",
        "    load_data_verbose = False,\n",
        "    # kwargs fed to `tss_pipeline_for_one_ontology`\n",
        "    train_params = TrainingParameters(),\n",
        "    model_params = ModelParameters(),\n",
        "    lr_verbose = 0,\n",
        "    train_verbose = 0,\n",
        "    checkpoint_verbose = 0,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1kqIojjURIy"
      },
      "outputs": [],
      "source": [
        "model_name = \"protgoat\"\n",
        "\n",
        "# Specify the file paths of the TSV files to concatenate\n",
        "ontology_prediction_filepaths = [\n",
        "    os.path.join(\n",
        "        PREDICTION_DIR,\n",
        "        ONTOLOGY_TSS_PREDICTION_TEMPLATE.format(ontology=ontology, model_name=model_name))\n",
        "    for ontology in BRANCH_ABBR.values()\n",
        "]\n",
        "\n",
        "# Read & Concatenate the DataFrames\n",
        "concatenated_df = (\n",
        "    pd.concat([\n",
        "        pd.read_csv(filepath, sep='\\t', header=None, names=[\"Protein Id\", \"GO Term Id\", \"Prediction\"])\n",
        "        for filepath in ontology_prediction_filepaths\n",
        "    ], ignore_index=True)\n",
        "    .sort_values([\"Protein Id\", \"GO Term Id\"])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "-6SliBMoURIy",
        "outputId": "2ba404fe-7e73-4dd4-9732-1051c60eb0f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Protein Id  GO Term Id  Prediction\n",
              "422645  A0A023FBW4  GO:0000002         1.0\n",
              "421566  A0A023FBW4  GO:0000003         1.0\n",
              "422473  A0A023FBW4  GO:0000018         1.0\n",
              "422821  A0A023FBW4  GO:0000038         1.0\n",
              "422159  A0A023FBW4  GO:0000041         1.0\n",
              "...            ...         ...         ...\n",
              "783046      X2JI34  GO:2001020         1.0\n",
              "783053      X2JI34  GO:2001057         1.0\n",
              "783414      X2JI34  GO:2001141         1.0\n",
              "783508      X2JI34  GO:2001222         1.0\n",
              "783207      X2JI34  GO:2001233         1.0\n",
              "\n",
              "[1586040 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-056a15cb-63b9-431e-b8c7-e9fe646f37dc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Protein Id</th>\n",
              "      <th>GO Term Id</th>\n",
              "      <th>Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>422645</th>\n",
              "      <td>A0A023FBW4</td>\n",
              "      <td>GO:0000002</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421566</th>\n",
              "      <td>A0A023FBW4</td>\n",
              "      <td>GO:0000003</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422473</th>\n",
              "      <td>A0A023FBW4</td>\n",
              "      <td>GO:0000018</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422821</th>\n",
              "      <td>A0A023FBW4</td>\n",
              "      <td>GO:0000038</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422159</th>\n",
              "      <td>A0A023FBW4</td>\n",
              "      <td>GO:0000041</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>783046</th>\n",
              "      <td>X2JI34</td>\n",
              "      <td>GO:2001020</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>783053</th>\n",
              "      <td>X2JI34</td>\n",
              "      <td>GO:2001057</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>783414</th>\n",
              "      <td>X2JI34</td>\n",
              "      <td>GO:2001141</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>783508</th>\n",
              "      <td>X2JI34</td>\n",
              "      <td>GO:2001222</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>783207</th>\n",
              "      <td>X2JI34</td>\n",
              "      <td>GO:2001233</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1586040 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-056a15cb-63b9-431e-b8c7-e9fe646f37dc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-056a15cb-63b9-431e-b8c7-e9fe646f37dc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-056a15cb-63b9-431e-b8c7-e9fe646f37dc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3f19f7ef-977e-4f32-9518-2640e47433cf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3f19f7ef-977e-4f32-9518-2640e47433cf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3f19f7ef-977e-4f32-9518-2640e47433cf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "concat_pred_df"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "concat_pred_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqH4AalrURIz",
        "outputId": "91621e4a-2ded-46ac-e0fd-9fbef7f89505"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GO:0050896</th>\n",
              "      <th>GO:0008152</th>\n",
              "      <th>GO:0032501</th>\n",
              "      <th>GO:0032502</th>\n",
              "      <th>GO:0065007</th>\n",
              "      <th>GO:0051179</th>\n",
              "      <th>GO:0009987</th>\n",
              "      <th>GO:0071840</th>\n",
              "      <th>GO:0023052</th>\n",
              "      <th>GO:0000003</th>\n",
              "      <th>...</th>\n",
              "      <th>GO:0051775</th>\n",
              "      <th>GO:0042149</th>\n",
              "      <th>GO:0006547</th>\n",
              "      <th>GO:0090659</th>\n",
              "      <th>GO:1901137</th>\n",
              "      <th>GO:1990845</th>\n",
              "      <th>GO:0031325</th>\n",
              "      <th>GO:0034067</th>\n",
              "      <th>GO:0060259</th>\n",
              "      <th>GO:0071887</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>E7EZG2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q9VX31</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>O48573</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q10MX2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F4KB79</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q57ZC7</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>O65370</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q9CA69</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q9FFX6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q1LXR6</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10993 rows × 1500 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        GO:0050896  GO:0008152  GO:0032501  GO:0032502  GO:0065007  \\\n",
              "E7EZG2           0           0           1           1           0   \n",
              "Q9VX31           0           0           0           0           1   \n",
              "O48573           1           0           1           1           1   \n",
              "Q10MX2           1           1           0           0           1   \n",
              "F4KB79           0           1           0           0           0   \n",
              "...            ...         ...         ...         ...         ...   \n",
              "Q57ZC7           0           1           0           0           0   \n",
              "O65370           0           0           1           1           1   \n",
              "Q9CA69           0           0           0           0           0   \n",
              "Q9FFX6           0           0           0           1           0   \n",
              "Q1LXR6           0           1           0           0           1   \n",
              "\n",
              "        GO:0051179  GO:0009987  GO:0071840  GO:0023052  GO:0000003  ...  \\\n",
              "E7EZG2           0           1           1           0           0  ...   \n",
              "Q9VX31           0           0           0           0           0  ...   \n",
              "O48573           1           1           1           1           0  ...   \n",
              "Q10MX2           0           1           0           0           0  ...   \n",
              "F4KB79           0           1           0           0           0  ...   \n",
              "...            ...         ...         ...         ...         ...  ...   \n",
              "Q57ZC7           0           1           0           0           0  ...   \n",
              "O65370           0           0           0           0           0  ...   \n",
              "Q9CA69           0           1           1           0           0  ...   \n",
              "Q9FFX6           0           0           0           0           0  ...   \n",
              "Q1LXR6           0           1           0           0           0  ...   \n",
              "\n",
              "        GO:0051775  GO:0042149  GO:0006547  GO:0090659  GO:1901137  \\\n",
              "E7EZG2           0           0           0           0           0   \n",
              "Q9VX31           0           0           0           0           0   \n",
              "O48573           0           0           0           0           0   \n",
              "Q10MX2           0           0           0           0           0   \n",
              "F4KB79           0           0           0           0           1   \n",
              "...            ...         ...         ...         ...         ...   \n",
              "Q57ZC7           0           0           0           0           0   \n",
              "O65370           0           0           0           0           0   \n",
              "Q9CA69           0           0           0           0           0   \n",
              "Q9FFX6           0           0           0           0           0   \n",
              "Q1LXR6           0           0           0           0           0   \n",
              "\n",
              "        GO:1990845  GO:0031325  GO:0034067  GO:0060259  GO:0071887  \n",
              "E7EZG2           0           0           0           0           0  \n",
              "Q9VX31           0           0           0           0           0  \n",
              "O48573           0           0           0           0           0  \n",
              "Q10MX2           0           0           0           0           0  \n",
              "F4KB79           0           0           0           0           0  \n",
              "...            ...         ...         ...         ...         ...  \n",
              "Q57ZC7           0           0           0           0           0  \n",
              "O65370           0           0           0           0           0  \n",
              "Q9CA69           0           0           0           0           0  \n",
              "Q9FFX6           0           0           0           0           0  \n",
              "Q1LXR6           0           0           0           0           0  \n",
              "\n",
              "[10993 rows x 1500 columns]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ground_truths[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoD0z-F8URIz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "_OJJ6va6URIz",
        "outputId": "df83ae00-89e0-4c36-c719-fcbb16dc8a93"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'create_PROTGOAT' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-70da6145070b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m final_predictions = cv_pipeline_for_all_ontologies(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcreate_PROTGOAT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"protgoat\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mload_data_verbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# kwargs fed to `pipeline_for_one_ontology`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'create_PROTGOAT' is not defined"
          ]
        }
      ],
      "source": [
        "final_predictions = cv_pipeline_for_all_ontologies(\n",
        "    create_PROTGOAT,\n",
        "    \"protgoat\",\n",
        "    load_data_verbose = False,\n",
        "    # kwargs fed to `pipeline_for_one_ontology`\n",
        "    train_params = TrainingParameters(),\n",
        "    model_params = ModelParameters(),\n",
        "    cv_params = CrossValidationParameters(),\n",
        "    lr_verbose = 0,\n",
        "    train_verbose = 0,\n",
        "    checkpoint_verbose = 0,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VqahEwUURIz",
        "outputId": "2e94bbb3-9c9d-4ef0-b8cc-db9e3061a982"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Protein Id</th>\n",
              "      <th>GO Term Id</th>\n",
              "      <th>Prediction</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>129971</th>\n",
              "      <td>[0 0 0 ... 0 0 0]</td>\n",
              "      <td>GO:0006082</td>\n",
              "      <td>0.000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126316</th>\n",
              "      <td>[0 0 0 ... 0 0 0]</td>\n",
              "      <td>GO:0006629</td>\n",
              "      <td>0.001</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128600</th>\n",
              "      <td>[0 0 0 ... 0 0 0]</td>\n",
              "      <td>GO:0006629</td>\n",
              "      <td>0.001</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117882</th>\n",
              "      <td>[0 0 0 ... 0 0 0]</td>\n",
              "      <td>GO:0006725</td>\n",
              "      <td>0.006</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120095</th>\n",
              "      <td>[0 0 0 ... 0 0 0]</td>\n",
              "      <td>GO:0006725</td>\n",
              "      <td>0.004</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>902596</th>\n",
              "      <td>[1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0...</td>\n",
              "      <td>GO:0005515</td>\n",
              "      <td>1.000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887705</th>\n",
              "      <td>[1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0...</td>\n",
              "      <td>GO:0005488</td>\n",
              "      <td>1.000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887706</th>\n",
              "      <td>[1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0...</td>\n",
              "      <td>GO:0005515</td>\n",
              "      <td>1.000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889676</th>\n",
              "      <td>[1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0...</td>\n",
              "      <td>GO:0005488</td>\n",
              "      <td>1.000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889677</th>\n",
              "      <td>[1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0...</td>\n",
              "      <td>GO:0005515</td>\n",
              "      <td>1.000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>910505 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Protein Id  GO Term Id  \\\n",
              "129971                                  [0 0 0 ... 0 0 0]  GO:0006082   \n",
              "126316                                  [0 0 0 ... 0 0 0]  GO:0006629   \n",
              "128600                                  [0 0 0 ... 0 0 0]  GO:0006629   \n",
              "117882                                  [0 0 0 ... 0 0 0]  GO:0006725   \n",
              "120095                                  [0 0 0 ... 0 0 0]  GO:0006725   \n",
              "...                                                   ...         ...   \n",
              "902596  [1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0...  GO:0005515   \n",
              "887705  [1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0...  GO:0005488   \n",
              "887706  [1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0...  GO:0005515   \n",
              "889676  [1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0...  GO:0005488   \n",
              "889677  [1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0...  GO:0005515   \n",
              "\n",
              "        Prediction  fold  \n",
              "129971       0.000     5  \n",
              "126316       0.001     5  \n",
              "128600       0.001     5  \n",
              "117882       0.006     5  \n",
              "120095       0.004     5  \n",
              "...            ...   ...  \n",
              "902596       1.000     5  \n",
              "887705       1.000     5  \n",
              "887706       1.000     5  \n",
              "889676       1.000     5  \n",
              "889677       1.000     5  \n",
              "\n",
              "[910505 rows x 4 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDjP9g-aURIz",
        "outputId": "a336046e-0cc8-4a10-a396-9c718a637243"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5it [13:38, 163.74s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4434/4434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step\n",
            "\u001b[1m4434/4434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step\n",
            "\u001b[1m4434/4434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step\n",
            "\u001b[1m4434/4434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step\n",
            "\u001b[1m4434/4434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5it [10:21, 124.36s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4434/4434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step\n",
            "\u001b[1m4434/4434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step\n",
            "\u001b[1m4434/4434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step\n",
            "\u001b[1m4434/4434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step\n",
            "\u001b[1m4434/4434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5it [08:37, 103.43s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4434/4434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step\n",
            "\u001b[1m4434/4434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step\n",
            "\u001b[1m4434/4434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step\n",
            "\u001b[1m4434/4434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step\n",
            "\u001b[1m4434/4434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step\n"
          ]
        }
      ],
      "source": [
        "final_submission = pipeline_for_all_ontologies(\n",
        "    create_PROTGOAT,\n",
        "    \"protgoat\",\n",
        "    # kwargs fed to `pipeline_for_one_ontology`\n",
        "    train_params = TrainingParameters(),\n",
        "    model_params = ModelParameters(),\n",
        "    cv_params = CrossValidationParameters(),\n",
        "    lr_verbose = 0,\n",
        "    train_verbose = 0,\n",
        "    checkpoint_verbose = 0,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmZ5k_tyURI0",
        "outputId": "27ec5b93-70ed-468d-9cd4-8c144dd688f6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Protein Id</th>\n",
              "      <th>GO Term Id</th>\n",
              "      <th>Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11160282</th>\n",
              "      <td>A0A023PXA5</td>\n",
              "      <td>GO:0045111</td>\n",
              "      <td>0.400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16740506</th>\n",
              "      <td>A0A023PXA5</td>\n",
              "      <td>GO:0048038</td>\n",
              "      <td>0.200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16740507</th>\n",
              "      <td>A0A023PXA5</td>\n",
              "      <td>GO:0038191</td>\n",
              "      <td>0.200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16740508</th>\n",
              "      <td>A0A023PXA5</td>\n",
              "      <td>GO:0016709</td>\n",
              "      <td>0.200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16740509</th>\n",
              "      <td>A0A023PXA5</td>\n",
              "      <td>GO:0031681</td>\n",
              "      <td>0.200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10876116</th>\n",
              "      <td>X6R8R1</td>\n",
              "      <td>GO:0005622</td>\n",
              "      <td>0.600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10734870</th>\n",
              "      <td>X6R8R1</td>\n",
              "      <td>GO:0110165</td>\n",
              "      <td>0.601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10876115</th>\n",
              "      <td>X6R8R1</td>\n",
              "      <td>GO:0071944</td>\n",
              "      <td>0.600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16739866</th>\n",
              "      <td>X6R8R1</td>\n",
              "      <td>GO:0003824</td>\n",
              "      <td>0.400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16438723</th>\n",
              "      <td>X6R8R1</td>\n",
              "      <td>GO:0005488</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21988920 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Protein Id  GO Term Id  Prediction\n",
              "11160282  A0A023PXA5  GO:0045111       0.400\n",
              "16740506  A0A023PXA5  GO:0048038       0.200\n",
              "16740507  A0A023PXA5  GO:0038191       0.200\n",
              "16740508  A0A023PXA5  GO:0016709       0.200\n",
              "16740509  A0A023PXA5  GO:0031681       0.200\n",
              "...              ...         ...         ...\n",
              "10876116      X6R8R1  GO:0005622       0.600\n",
              "10734870      X6R8R1  GO:0110165       0.601\n",
              "10876115      X6R8R1  GO:0071944       0.600\n",
              "16739866      X6R8R1  GO:0003824       0.400\n",
              "16438723      X6R8R1  GO:0005488       1.000\n",
              "\n",
              "[21988920 rows x 3 columns]"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad9acft_URI0"
      },
      "source": [
        "### Plot model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osH77foqURI0"
      },
      "outputs": [],
      "source": [
        "def plot_specified_model(model_name: str, ontology: str, fold: int, rand_seed: int = 0) -> None:\n",
        "    # Load the model\n",
        "    model_path = os.path.join(MODEL_SAVE_DIR, f\"{model_name}_{ontology}_fc{fold}_r{rand_seed}.keras\")\n",
        "    model = load_model(model_path)\n",
        "    # Plot the model\n",
        "    return plot_model(model, show_shapes=True, show_layer_names=True) # to_file='model.png',"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "PSjtbg-mvQEv",
        "outputId": "d1b5e9c5-3790-4033-8134-41c56057d97a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "File not found: filepath=models/struct_protgoat_CCO_fc2_r0.keras. Please ensure the file is an accessible `.keras` zip file.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-ed309741e8f0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Choose the model to plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_specified_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"struct_protgoat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0montology\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CCO\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-41-ae1cc584b801>\u001b[0m in \u001b[0;36mplot_specified_model\u001b[0;34m(model_name, ontology, fold, rand_seed)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Load the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_SAVE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{model_name}_{ontology}_fc{fold}_r{rand_seed}.keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Plot the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# to_file='model.png',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    185\u001b[0m         )\n\u001b[1;32m    186\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0;34mf\"File not found: filepath={filepath}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;34m\"Please ensure the file is an accessible `.keras` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: File not found: filepath=models/struct_protgoat_CCO_fc2_r0.keras. Please ensure the file is an accessible `.keras` zip file."
          ]
        }
      ],
      "source": [
        "# Choose the model to plot\n",
        "plot_specified_model(model_name=\"struct_protgoat\", ontology=\"CCO\", fold=2, rand_seed=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30IHxRMoURI1"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdscRNTdURI1"
      },
      "source": [
        "The result of the predictions are evaluated following CAFA standards using a special F-max score, as mentioned in the [CAFA-evaluator Github](https://github.com/BioComputingUP/CAFA-evaluator)\n",
        "\n",
        "It evaluates the performance of prediction methods on targets with hierarchical concept dependencies. It generalizes multi-label evaluation to modern ontologies where the prediction targets are drawn from a directed acyclic graph and achieves high efficiency by leveraging matrix computation and topological sorting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-bCsoUFURI1"
      },
      "outputs": [],
      "source": [
        "def AUPRC(y_test, probas_pred):\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, probas_pred)\n",
        "    return auc(recall, precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izyVb0mjURI1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kc8SZlytURI1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVnVnSjCURI1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Emq-DfYqURI2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WupeZTfqURI2"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}